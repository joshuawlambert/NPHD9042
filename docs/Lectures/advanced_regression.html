<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.433">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Dr.&nbsp;Joshua Lambert">

<title>NPHD 9042 – Applied Multivariate Analysis - Model Building and Advanced Linear and Logistic Regression</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


<link rel="stylesheet" href="../styles.css">
<link rel="stylesheet" href="styles.css">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="../index.html">
    <span class="navbar-title">NPHD 9042 – Applied Multivariate Analysis</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../index.html" rel="" target="">
 <span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../Other/syl.html" rel="" target="">
 <span class="menu-text">Syllabus</span></a>
  </li>  
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-lectures" role="button" data-bs-toggle="dropdown" aria-expanded="false" rel="" target="">
 <span class="menu-text">Lectures</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-lectures">    
        <li>
    <a class="dropdown-item" href="../Lectures/introduction-to-multivariate.html" rel="" target="">
 <span class="dropdown-text">Introduction to Multivariate Analysis</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../Lectures/introduction-to-EFA.html" rel="" target="">
 <span class="dropdown-text">Introduction to Exploratory Factor Analysis(EFA)</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../Lectures/advanced_regression.html" rel="" target="">
 <span class="dropdown-text">Advanced Regression and Model Building</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../Lectures/introduction-to-SEM.html" rel="" target="">
 <span class="dropdown-text">Introduction to Structual Equation Modeling (SEM)</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../Lectures/introduction-to-CFA-PA.html" rel="" target="">
 <span class="dropdown-text">Introduction to Confirmatory Factor Analysis (CFA) and Path Analysis (PA)</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../Lectures/introduction-to-CART.html" rel="" target="">
 <span class="dropdown-text">Introduction to Classifcation and Regression Tree (CART)</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../Lectures/writing.html" rel="" target="">
 <span class="dropdown-text">Writing Guide for Academic Writers</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item">
    <a class="nav-link" href="../Flashcards/VocabJargon.html" rel="" target="">
 <span class="menu-text">Vocabulary &amp; Jargon</span></a>
  </li>  
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-assignments" role="button" data-bs-toggle="dropdown" aria-expanded="false" rel="" target="">
 <span class="menu-text">Assignments</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-assignments">    
        <li>
    <a class="dropdown-item" href="../Assignments/hw1.html" rel="" target="">
 <span class="dropdown-text">HW 1</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../Assignments/hw2.html" rel="" target="">
 <span class="dropdown-text">HW 2</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../Assignments/hw3.html" rel="" target="">
 <span class="dropdown-text">HW 3</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../Assignments/hw4.html" rel="" target="">
 <span class="dropdown-text">HW 4</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../Assignments/MidtermProject.html" rel="" target="">
 <span class="dropdown-text">Midterm Project</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../Assignments/FinalProject.html" rel="" target="">
 <span class="dropdown-text">Final Project</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item">
    <a class="nav-link" href="../Articles/articles.html" rel="" target="">
 <span class="menu-text">Articles</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../Other/aboutDrL.html" rel="" target="">
 <span class="menu-text">About Dr.&nbsp;L</span></a>
  </li>  
</ul>
            <div class="quarto-navbar-tools ms-auto">
</div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of Contents</h2>
   
  <ul>
  <li><a href="#model-building-and-advanced-linear-and-logistic-regression" id="toc-model-building-and-advanced-linear-and-logistic-regression" class="nav-link active" data-scroll-target="#model-building-and-advanced-linear-and-logistic-regression">Model Building and Advanced Linear and Logistic Regression</a>
  <ul class="collapse">
  <li><a href="#definition-and-purpose-of-multiple-linear-and-logistic-regression-analysis" id="toc-definition-and-purpose-of-multiple-linear-and-logistic-regression-analysis" class="nav-link" data-scroll-target="#definition-and-purpose-of-multiple-linear-and-logistic-regression-analysis">Definition and Purpose of Multiple Linear and Logistic Regression Analysis</a>
  <ul class="collapse">
  <li><a href="#multiple-linear-regression" id="toc-multiple-linear-regression" class="nav-link" data-scroll-target="#multiple-linear-regression">Multiple Linear Regression</a></li>
  <li><a href="#logistic-regression" id="toc-logistic-regression" class="nav-link" data-scroll-target="#logistic-regression">Logistic Regression</a></li>
  </ul></li>
  <li><a href="#key-assumptions-and-limitations" id="toc-key-assumptions-and-limitations" class="nav-link" data-scroll-target="#key-assumptions-and-limitations">Key Assumptions and Limitations</a>
  <ul class="collapse">
  <li><a href="#multiple-linear-regression-assumptions" id="toc-multiple-linear-regression-assumptions" class="nav-link" data-scroll-target="#multiple-linear-regression-assumptions">Multiple Linear Regression Assumptions</a></li>
  </ul></li>
  <li><a href="#dependent-variable" id="toc-dependent-variable" class="nav-link" data-scroll-target="#dependent-variable">Dependent Variable</a></li>
  <li><a href="#independent-variables" id="toc-independent-variables" class="nav-link" data-scroll-target="#independent-variables">Independent Variables</a></li>
  <li><a href="#variable-selection-techniques" id="toc-variable-selection-techniques" class="nav-link" data-scroll-target="#variable-selection-techniques">Variable Selection Techniques</a>
  <ul class="collapse">
  <li><a href="#forward-selection" id="toc-forward-selection" class="nav-link" data-scroll-target="#forward-selection">Forward Selection</a></li>
  <li><a href="#backward-selection" id="toc-backward-selection" class="nav-link" data-scroll-target="#backward-selection">Backward Selection</a></li>
  <li><a href="#stepwise-selection" id="toc-stepwise-selection" class="nav-link" data-scroll-target="#stepwise-selection">Stepwise Selection</a></li>
  <li><a href="#lasso-least-absolute-shrinkage-and-selection-operator" id="toc-lasso-least-absolute-shrinkage-and-selection-operator" class="nav-link" data-scroll-target="#lasso-least-absolute-shrinkage-and-selection-operator">Lasso (Least Absolute Shrinkage and Selection Operator)</a></li>
  <li><a href="#multi-step-hierarchical-regression" id="toc-multi-step-hierarchical-regression" class="nav-link" data-scroll-target="#multi-step-hierarchical-regression">Multi-Step (Hierarchical Regression)</a></li>
  </ul></li>
  <li><a href="#understanding-coefficients" id="toc-understanding-coefficients" class="nav-link" data-scroll-target="#understanding-coefficients">Understanding Coefficients</a></li>
  <li><a href="#significance-and-confidence-intervals" id="toc-significance-and-confidence-intervals" class="nav-link" data-scroll-target="#significance-and-confidence-intervals">Significance and Confidence Intervals</a></li>
  <li><a href="#common-criterion-r-squared-and-adjusted-r-squared-and-other-model-fit-statistics" id="toc-common-criterion-r-squared-and-adjusted-r-squared-and-other-model-fit-statistics" class="nav-link" data-scroll-target="#common-criterion-r-squared-and-adjusted-r-squared-and-other-model-fit-statistics">Common Criterion: R-Squared and Adjusted R-Squared, and Other Model Fit Statistics</a>
  <ul class="collapse">
  <li><a href="#multiple-linear-regression-1" id="toc-multiple-linear-regression-1" class="nav-link" data-scroll-target="#multiple-linear-regression-1">Multiple Linear Regression</a></li>
  <li><a href="#logistic-regression-1" id="toc-logistic-regression-1" class="nav-link" data-scroll-target="#logistic-regression-1">Logistic Regression</a></li>
  </ul></li>
  <li><a href="#residual-analysis" id="toc-residual-analysis" class="nav-link" data-scroll-target="#residual-analysis">Residual Analysis</a>
  <ul class="collapse">
  <li><a href="#normality-of-residuals" id="toc-normality-of-residuals" class="nav-link" data-scroll-target="#normality-of-residuals">Normality of Residuals</a></li>
  <li><a href="#homoscedasticity" id="toc-homoscedasticity" class="nav-link" data-scroll-target="#homoscedasticity">Homoscedasticity</a></li>
  </ul></li>
  <li><a href="#diagnostic-plots" id="toc-diagnostic-plots" class="nav-link" data-scroll-target="#diagnostic-plots">Diagnostic Plots</a></li>
  <li><a href="#examples-of-model-building-in-multiple-linear-and-logistic-regression" id="toc-examples-of-model-building-in-multiple-linear-and-logistic-regression" class="nav-link" data-scroll-target="#examples-of-model-building-in-multiple-linear-and-logistic-regression">Examples of Model Building in Multiple Linear and Logistic Regression</a>
  <ul class="collapse">
  <li><a href="#multiple-linear-regression-example" id="toc-multiple-linear-regression-example" class="nav-link" data-scroll-target="#multiple-linear-regression-example">Multiple Linear Regression Example</a></li>
  <li><a href="#logistic-regression-example" id="toc-logistic-regression-example" class="nav-link" data-scroll-target="#logistic-regression-example">Logistic Regression Example</a></li>
  </ul></li>
  <li><a href="#software-examples" id="toc-software-examples" class="nav-link" data-scroll-target="#software-examples">Software Examples</a>
  <ul class="collapse">
  <li><a href="#forward-selection-1" id="toc-forward-selection-1" class="nav-link" data-scroll-target="#forward-selection-1">Forward Selection</a></li>
  <li><a href="#backward-selection-1" id="toc-backward-selection-1" class="nav-link" data-scroll-target="#backward-selection-1">Backward Selection</a></li>
  <li><a href="#stepwise-selection-1" id="toc-stepwise-selection-1" class="nav-link" data-scroll-target="#stepwise-selection-1">Stepwise Selection</a></li>
  <li><a href="#lasso" id="toc-lasso" class="nav-link" data-scroll-target="#lasso">Lasso</a></li>
  <li><a href="#multi-step-hierarchical-regression-1" id="toc-multi-step-hierarchical-regression-1" class="nav-link" data-scroll-target="#multi-step-hierarchical-regression-1">Multi-Step (Hierarchical Regression)</a></li>
  </ul></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<div class="quarto-title-block"><div><h1 class="title">Model Building and Advanced Linear and Logistic Regression</h1><button type="button" class="btn code-tools-button" id="quarto-code-tools-source"><i class="bi"></i> Code</button></div></div>
</div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Dr.&nbsp;Joshua Lambert </p>
          </div>
  </div>
    
  
    
  </div>
  

</header>

<section id="model-building-and-advanced-linear-and-logistic-regression" class="level1">
<h1>Model Building and Advanced Linear and Logistic Regression</h1>
<p>Understanding the fundamentals and advanced topics of multiple linear and logistic regression analysis is crucial for nursing research. This page will cover the definitions, key concepts, assumptions, and techniques required to build robust models in these contexts.</p>
<section id="definition-and-purpose-of-multiple-linear-and-logistic-regression-analysis" class="level2">
<h2 class="anchored" data-anchor-id="definition-and-purpose-of-multiple-linear-and-logistic-regression-analysis">Definition and Purpose of Multiple Linear and Logistic Regression Analysis</h2>
<section id="multiple-linear-regression" class="level3">
<h3 class="anchored" data-anchor-id="multiple-linear-regression">Multiple Linear Regression</h3>
<ul>
<li><strong>Definition</strong>: A statistical technique that models the relationship between a dependent variable and two or more independent variables by fitting a linear equation.</li>
<li><strong>Purpose</strong>: To predict the value of the dependent variable based on the values of the independent variables and to understand the relationship between them.</li>
</ul>
</section>
<section id="logistic-regression" class="level3">
<h3 class="anchored" data-anchor-id="logistic-regression">Logistic Regression</h3>
<ul>
<li><strong>Definition</strong>: A regression model where the dependent variable is categorical, typically binary.</li>
<li><strong>Purpose</strong>: To model the probability of a binary outcome based on one or more predictor variables.</li>
</ul>
</section>
</section>
<section id="key-assumptions-and-limitations" class="level2">
<h2 class="anchored" data-anchor-id="key-assumptions-and-limitations">Key Assumptions and Limitations</h2>
<section id="multiple-linear-regression-assumptions" class="level3">
<h3 class="anchored" data-anchor-id="multiple-linear-regression-assumptions">Multiple Linear Regression Assumptions</h3>
<ul>
<li><p><strong>Linearity</strong>: The relationship between the dependent and independent variables should be linear.</p></li>
<li><p><strong>Independence</strong>: Observations should be independent of each other.</p></li>
<li><p><strong>Homoscedasticity</strong>: The variance of error terms should be constant across all levels of the independent variables.</p></li>
<li><p><strong>Normality</strong>: The residuals (errors) should be approximately normally distributed.</p></li>
<li><p><strong>Absence of Multicollinearity</strong>: Predictors should not be too highly correlated with each other.</p></li>
<li><p><strong>Independence</strong>: Observations should be independent. ### Logistic Regression Assumptions</p></li>
<li><p><strong>Linearity of Logit</strong>: The logit of the outcome should have a linear relationship with the predictor variables.</p></li>
<li><p><strong>Independence</strong>: Observations should be independent.</p></li>
<li><p><strong>Absence of Multicollinearity</strong>: Predictors should not be too highly correlated with each other.</p></li>
</ul>
</section>
</section>
<section id="dependent-variable" class="level2">
<h2 class="anchored" data-anchor-id="dependent-variable">Dependent Variable</h2>
<ul>
<li><strong>Multiple Linear Regression</strong>: A continuous variable (e.g., blood pressure, cholesterol level).</li>
<li><strong>Logistic Regression</strong>: A categorical variable (e.g., presence or absence of a disease).</li>
</ul>
</section>
<section id="independent-variables" class="level2">
<h2 class="anchored" data-anchor-id="independent-variables">Independent Variables</h2>
<ul>
<li><strong>Definition</strong>: Variables that predict or explain the dependent variable. Can be continuous or categorical.</li>
<li><strong>Examples in Nursing Research</strong>: Age, weight, treatment type, comorbidities.</li>
</ul>
</section>
<section id="variable-selection-techniques" class="level2">
<h2 class="anchored" data-anchor-id="variable-selection-techniques">Variable Selection Techniques</h2>
<section id="forward-selection" class="level3">
<h3 class="anchored" data-anchor-id="forward-selection">Forward Selection</h3>
<p><img src="https://quantifyinghealth.com/wp-content/uploads/2019/10/forward-stepwise-algorithm.png" class="img-fluid"></p>
<ul>
<li><strong>Method</strong>: Starts with no predictors and adds them one by one based on a specified criterion (e.g., p-value).</li>
<li><strong>Process</strong>:
<ul>
<li>Begin with an empty model.</li>
<li>Add the predictor with the best criterion (e.g.&nbsp;lowest p-value).</li>
<li>Continue adding predictors one at a time, based on criterion, until no additional predictors meet the criterion.</li>
</ul></li>
<li><strong>Advantages</strong>: Simple and easy to understand.</li>
<li><strong>Disadvantages</strong>: Can miss important variables that only show their effect in combination with others. Using p-values to add variables can lead to incorrect model specification. Other methods like AIC, or BIC can perform better.</li>
</ul>
</section>
<section id="backward-selection" class="level3">
<h3 class="anchored" data-anchor-id="backward-selection">Backward Selection</h3>
<p><img src="https://quantifyinghealth.com/wp-content/uploads/2019/10/backward-stepwise-algorithm.png" class="img-fluid"></p>
<ul>
<li><strong>Method</strong>: Starts with all candidate predictors and removes them one by one based on a specified criterion.</li>
<li><strong>Process</strong>:
<ul>
<li>Begin with the full model.</li>
<li>Remove the predictor with the worst criterion.</li>
<li>Continue removing predictors until all remaining predictors meet criterion.</li>
</ul></li>
<li><strong>Advantages</strong>: Considers the full model from the start.</li>
<li><strong>Disadvantages</strong>: Computationally intensive for large set of candidate predictors.</li>
</ul>
</section>
<section id="stepwise-selection" class="level3">
<h3 class="anchored" data-anchor-id="stepwise-selection">Stepwise Selection</h3>
<ul>
<li><strong>Method</strong>: A combination of forward and backward selection.</li>
<li><strong>Process</strong>:
<ul>
<li>Begin with an empty model or a model with a subset of predictors.</li>
<li>Add predictors based on criterion and remove predictors whose criterion no longer meets standard.</li>
<li>Continue until no predictors can be added or removed.</li>
</ul></li>
<li><strong>Advantages</strong>: More flexible and can result in a better model.</li>
<li><strong>Disadvantages</strong>: Prone to overfitting and can be unstable.</li>
</ul>
</section>
<section id="lasso-least-absolute-shrinkage-and-selection-operator" class="level3">
<h3 class="anchored" data-anchor-id="lasso-least-absolute-shrinkage-and-selection-operator">Lasso (Least Absolute Shrinkage and Selection Operator)</h3>
<p><img src="https://statmodeling.stat.columbia.edu/wp-content/uploads/2013/03/Screen-Shot-2013-03-17-at-10.43.11-PM.png" class="img-fluid"></p>
<ul>
<li><strong>Method</strong>: Performs both variable selection and regularization to enhance the prediction accuracy and interpretability.</li>
<li><strong>Process</strong>:
<ul>
<li>Adds a penalty to the size of the coefficients, shrinking some to zero and thus performing variable selection.</li>
<li>The amount of shrinkage is controlled by a tuning parameter (lambda).</li>
</ul></li>
<li><strong>Advantages</strong>: Can handle large sets of predictors and reduces overfitting.</li>
<li><strong>Disadvantages</strong>: Requires careful selection of the regularization parameter. Use cross validation to select.</li>
</ul>
</section>
<section id="multi-step-hierarchical-regression" class="level3">
<h3 class="anchored" data-anchor-id="multi-step-hierarchical-regression">Multi-Step (Hierarchical Regression)</h3>
<p><img src="https://www.researchgate.net/publication/287965810/figure/tbl1/AS:647170898284545@1531308974339/Hierarchical-regression-analysis-table.png" class="img-fluid"></p>
<ul>
<li><strong>Method</strong>: Involves entering predictors into the regression model in steps based on theoretical justification.</li>
<li><strong>Process</strong>:
<ul>
<li>Enter variables in a pre-specified order, typically based on theoretical importance.</li>
<li>Assess the contribution of each variable or set of variables at each step.</li>
</ul></li>
<li><strong>Advantages</strong>: Allows testing the incremental value of adding new predictors.</li>
<li><strong>Disadvantages</strong>: Can be complex to implement and interpret.</li>
<li><strong>Confusion with Hierarchical Models</strong>:
<ul>
<li>Hierarchical <em>regression</em> involves adding variables in steps to assess their incremental value.</li>
<li>Hierarchical <em>models</em> (also known as multilevel models) account for data that is nested within higher-level units (e.g., patients within hospitals).</li>
<li>Despite similar names, hierarchical regression and hierarchical models address different analytical needs.</li>
</ul></li>
</ul>
</section>
</section>
<section id="understanding-coefficients" class="level2">
<h2 class="anchored" data-anchor-id="understanding-coefficients">Understanding Coefficients</h2>
<ul>
<li><strong>Interpretation</strong>: Coefficients represent the change in the dependent variable for a one-unit change in the predictor variable, holding other variables constant.</li>
<li><strong>Logistic Regression</strong>: Coefficients are in terms of the log odds of the outcome. Once exponentiated, the coefficientsare in terms of change in odds of outcome.</li>
</ul>
</section>
<section id="significance-and-confidence-intervals" class="level2">
<h2 class="anchored" data-anchor-id="significance-and-confidence-intervals">Significance and Confidence Intervals</h2>
<ul>
<li><strong>P-Values</strong>: Indicate whether there is statistical evidence that the population parameter is significantly different from zero.</li>
<li><strong>Confidence Intervals</strong>: Provide a range of values within which the true population parameter is expected to fall. Based on a defined confidence level (e.g.&nbsp;95%)</li>
</ul>
</section>
<section id="common-criterion-r-squared-and-adjusted-r-squared-and-other-model-fit-statistics" class="level2">
<h2 class="anchored" data-anchor-id="common-criterion-r-squared-and-adjusted-r-squared-and-other-model-fit-statistics">Common Criterion: R-Squared and Adjusted R-Squared, and Other Model Fit Statistics</h2>
<section id="multiple-linear-regression-1" class="level3">
<h3 class="anchored" data-anchor-id="multiple-linear-regression-1">Multiple Linear Regression</h3>
<ul>
<li><strong>R-Squared</strong>: Measures the proportion of variability in the dependent variable that is explained by the independent variables. Problem is that as the number of variables increase the R-Squared will always increase.</li>
<li><strong>Adjusted R-Squared</strong>: Adjusts R-squared for the number of predictors in the model. Addresses problem previously mentioned.</li>
<li><strong>AIC/BIC (Akaike Information Criterion/Bayesian Information Criterion)</strong>: Used for model comparison, with lower values indicating a better fit and quality.</li>
</ul>
</section>
<section id="logistic-regression-1" class="level3">
<h3 class="anchored" data-anchor-id="logistic-regression-1">Logistic Regression</h3>
<ul>
<li><strong>Pseudo R-Squared</strong>: Analogous to R-squared in linear regression, but measures the goodness of fit for logistic models. Problem is that as the number of variables increase the R-Squared will always increase. Adjusted Pseudo R-Squared do exist.</li>
<li><strong>AIC/BIC (Akaike Information Criterion/Bayesian Information Criterion)</strong>: Used for model comparison, with lower values indicating a better fit and quality.</li>
</ul>
</section>
</section>
<section id="residual-analysis" class="level2">
<h2 class="anchored" data-anchor-id="residual-analysis">Residual Analysis</h2>
<section id="normality-of-residuals" class="level3">
<h3 class="anchored" data-anchor-id="normality-of-residuals">Normality of Residuals</h3>
<ul>
<li><strong>Importance</strong>: Ensures the validity of hypothesis tests and confidence intervals.</li>
<li><strong>Assessment</strong>: Histogram, Q-Q plot.</li>
</ul>
</section>
<section id="homoscedasticity" class="level3">
<h3 class="anchored" data-anchor-id="homoscedasticity">Homoscedasticity</h3>
<ul>
<li><strong>Importance</strong>: Ensures that the residuals have constant variance, which is an assumption of linear regression.</li>
<li><strong>Assessment</strong>: Residuals vs.&nbsp;fitted values plot.</li>
</ul>
</section>
</section>
<section id="diagnostic-plots" class="level2">
<h2 class="anchored" data-anchor-id="diagnostic-plots">Diagnostic Plots</h2>
<ul>
<li><strong>Residual Plots</strong>: Help assess the assumptions of linearity, homoscedasticity, and independence.</li>
<li><strong>Influence Plots</strong>: Identify influential data points that can disproportionately affect the model.</li>
</ul>
</section>
<section id="examples-of-model-building-in-multiple-linear-and-logistic-regression" class="level2">
<h2 class="anchored" data-anchor-id="examples-of-model-building-in-multiple-linear-and-logistic-regression">Examples of Model Building in Multiple Linear and Logistic Regression</h2>
<section id="multiple-linear-regression-example" class="level3">
<h3 class="anchored" data-anchor-id="multiple-linear-regression-example">Multiple Linear Regression Example</h3>
<ul>
<li><strong>Scenario</strong>: Predicting calories of common breakfast cereal based on nutritional information.</li>
<li>Use the <a href="Cereal.csv" download="">Cereal datatset to run the multiple linear regression.</a></li>
</ul>
</section>
<section id="logistic-regression-example" class="level3">
<h3 class="anchored" data-anchor-id="logistic-regression-example">Logistic Regression Example</h3>
<ul>
<li><strong>Scenario</strong>: Predicting the likelihood of domestic vehicle manufacture based on vehicle characteristics.</li>
<li>Use the <a href="Cars 1993.csv" download=""> Cars 1993.csv</a> dataset to run the logistic regression. This dataset contains information on 93 cars from the year 1993.</li>
</ul>
</section>
</section>
<section id="software-examples" class="level2">
<h2 class="anchored" data-anchor-id="software-examples">Software Examples</h2>
<section id="forward-selection-1" class="level3">
<h3 class="anchored" data-anchor-id="forward-selection-1">Forward Selection</h3>
<details>
<summary>
JMP Instructions:
</summary>
<ul>
<li>
Go to <code>Analyze</code> &gt; <code>Fit Model</code>.
</li>
<li>
Select your dependent variable and move it to the <code>Y</code> box.
</li>
<li>
Select your independent variables and move them to the <code>Construct Model Effects</code> box.
</li>
<li>
Click on the <code>Stepwise</code> button.
</li>
<li>
In the Stepwise Options dialog, set the <code>Direction</code> to <code>Forward</code>.
</li>
<li>
Specify the stopping criterion (e.g., p-value threshold.
</li>
<li>
Click <code>Run Model</code> to perform the forward selection.
</li>
</ul>
</details>
<details>
<summary>
R Code Example:
</summary>
<ul>
<li>
<pre>        #Forward selection for MLR
# Load necessary libraries
library(MASS)  

# Load dataset
cars1993&lt;-read_csv("Cars 1993.csv")

#Build the full model
full_model &lt;- lm(`Minimum Price ($1000)` ~ `Maximum Horsepower` + `Fuel Tank Capacity`+ `Passenger Capacity`, data = cars1993)

# Forward stepwise selection
step_model &lt;- stepAIC(lm(`Minimum Price ($1000)` ~ 1, data = cars1993), 
                      direction = "forward", 
                      scope = list(lower = ~1, upper = full_model))

# Print summary of the final model selected by forward selection
summary(step_model)
      </pre>
</li>
</ul>
</details>
<details>
<summary>
Python Code Example:
</summary>
<ul>
<li>
<pre>import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.datasets import load_iris
from sklearn.ensemble import RandomForestClassifier
from sklearn.feature_selection import SelectFromModel
from sklearn.linear_model import LinearRegression
import numpy as np

# Load iris data
iris = load_iris()
X = pd.DataFrame(iris.data, columns=iris.feature_names)
y = iris.target

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)

# Feature selection using Random Forest
rf = RandomForestClassifier(n_estimators=100, random_state=0)
sfm = SelectFromModel(rf, threshold='median')
X_train_selected = sfm.fit_transform(X_train, y_train)

# Get the selected feature indices
selected_feature_indices = sfm.get_support(indices=True)

# Get the selected feature names
selected_features = X_train.columns[selected_feature_indices]

def forward_selection(X_train, y_train, selected_features):
    remaining_features = set(selected_features)
    current_score = float('inf')
    best_new_score = float('inf')
    selected_features_list = [] # Use a list to store selected feature names
    
    while remaining_features:
        scores_with_candidates = []
        for candidate in remaining_features:
            # Add the candidate feature to the selected features
            selected_features_list.append(candidate)
            
            # Fit a model with the selected features
            # Use the list of selected feature names to index X_train
            model = LinearRegression().fit(X_train[selected_features_list], y_train) 
            
            # Calculate the AIC score
            RSS = sum((model.predict(X_train[selected_features_list]) - y_train) ** 2)
            n = len(X_train)
            p = len(selected_features_list)
            score = n * np.log(RSS / n) + 2 * p
            
            # Store the score and the candidate feature
            scores_with_candidates.append((score, candidate))
            
            # Remove the candidate feature from the selected features
            selected_features_list.pop()
        
        # Sort the scores and select the best candidate
        scores_with_candidates.sort()
        best_new_score, best_candidate = scores_with_candidates[0]
        
        # If the new score is better than the current score, update the current score and add the best candidate to the selected features
        if current_score &gt; best_new_score:
            current_score = best_new_score
            selected_features_list.append(best_candidate) # Append to the list
            remaining_features.remove(best_candidate)
    
    # Fit a model with the selected features
    # Index X_train with the list of selected feature names
    model = LinearRegression().fit(X_train[selected_features_list], y_train) 
    
    return model, selected_features_list # Return both the model and the list of selected features

# Run forward selection
# Pass the list of selected feature names to the function
model, selected_features_list = forward_selection(X_train, y_train, selected_features) 

# Print the summary of the model
print("Selected Features:", model.coef_)

# Print the selected feature column names
print("Selected Features:")
for feature in selected_features_list: # Iterate over the list of selected features
    print(feature)
      </pre>
</li>
</ul>
</details>
<details>
<summary>
STATA Code Example:
</summary>
<ul>
<li>
<pre>        // Forward Selection in STATA
        stepwise, pr(0.05): regress recovery_time age severity treatment gender comorbidities
      </pre>
</li>
</ul>
</details>
</section>
<section id="backward-selection-1" class="level3">
<h3 class="anchored" data-anchor-id="backward-selection-1">Backward Selection</h3>
<details>
<summary>
JMP Instructions:
</summary>
<ul>
<li>
Go to <code>Analyze</code> &gt; <code>Fit Model</code>.
</li>
<li>
Select your dependent variable and move it to the <code>Y</code> box.
</li>
<li>
Select your independent variables and move them to the <code>Construct Model Effects</code> box.
</li>
<li>
Click on the <code>Stepwise</code> button.
</li>
<li>
In the Stepwise Options dialog, set the <code>Direction</code> to <code>Backward</code>.
</li>
<li>
Specify the stopping criterion (e.g., p-value threshold) and click <code>OK</code>.
</li>
<li>
Click <code>Run</code> to perform the backward selection.
</li>
</ul>
</details>
<details>
<summary>
R Code Example:
</summary>
<ul>
<li>
<pre>        #Backward selection with MLR
# Load necessary libraries
library(MASS)  

# Load dataset
cars1993&lt;-read_csv("Cars 1993.csv")

#Build the full model
full_model &lt;- lm(`Minimum Price ($1000)` ~ `Maximum Horsepower` + `Fuel Tank Capacity`+ `Passenger Capacity`, data = cars1993)

# Backward stepwise selection
step_model &lt;- stepAIC(full_model, direction = "backward")

# Print summary of the final model selected by backward selection
summary(step_model)
  
      </pre>
</li>
</ul>
</details>
<details>
<summary>
Python Code Example:
</summary>
<ul>
<li>
<pre>import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.datasets import load_iris
from sklearn.feature_selection import SelectFromModel
from sklearn.linear_model import LinearRegression
import numpy as np
from sklearn.linear_model import Lasso

# Load iris data
iris = load_iris()
X = pd.DataFrame(iris.data, columns=iris.feature_names)
y = iris.target

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)


def backward_selection(X_train, y_train):
    remaining_features = set(X_train.columns)
    current_score = float('inf')
    selected_features_list = list(X_train.columns)
    
    # Change the model to Lasso for feature selection
    model = Lasso(alpha=0.01)
    
    while len(remaining_features) &gt; 1:
        scores_with_candidates = []
        for candidate in remaining_features:
            # Temporarily remove the candidate feature from the selected features
            selected_features_list.remove(candidate)
            
            # Fit the Lasso model with the remaining features
            model.fit(X_train[selected_features_list], y_train)
            
            # Calculate the AIC score
            RSS = sum((model.predict(X_train[selected_features_list]) - y_train) ** 2)
            n = len(X_train)
            p = len(selected_features_list)
            score = n * np.log(RSS / n) + 2 * p
            
            # Store the score and the candidate feature
            scores_with_candidates.append((score, candidate))
            
            # Add the candidate feature back to the selected features
            selected_features_list.append(candidate)
        
        # Sort the scores in ascending order
        scores_with_candidates.sort()
        
        # Select the candidate feature with the highest score
        _, worst_candidate = scores_with_candidates.pop(0)
        
        # If removing the worst candidate improves the score, remove it
        if scores_with_candidates[-1][0] &lt; current_score: 
            selected_features_list.remove(worst_candidate)
            remaining_features.remove(worst_candidate)
            current_score = scores_with_candidates[-1][0]
        else:
            break  # Early stopping if improvement becomes negligible
    
    # Fit the final Lasso model with the remaining features
    model.fit(X_train[selected_features_list], y_train)
    
    return model, selected_features_list

# Run backward selection
model, selected_features_list = backward_selection(X_train, y_train)

# Get the names of the selected features
selected_feature_names = selected_features_list

# Get the coefficients of the selected features
selected_feature_coefficients = model.coef_

# Print the summary of the selected features and their coefficients
for feature_name, coefficient in zip(selected_feature_names, selected_feature_coefficients):
    print("Feature:", feature_name, "| Coefficient:", coefficient)
      </pre>
</li>
</ul>
</details>
<details>
<summary>
STATA Code Example:
</summary>
<ul>
<li>
<pre>        // Backward Selection in STATA
        stepwise, pr(0.05) backward: regress recovery_time age severity treatment gender comorbidities
      </pre>
</li>
</ul>
</details>
</section>
<section id="stepwise-selection-1" class="level3">
<h3 class="anchored" data-anchor-id="stepwise-selection-1">Stepwise Selection</h3>
<details>
<summary>
JMP Instructions:
</summary>
<ul>
<li>
Go to <code>Analyze</code> &gt; <code>Fit Model</code>.
</li>
<li>
Select your dependent variable and move it to the <code>Y</code> box.
</li>
<li>
Select your independent variables and move them to the <code>Construct Model Effects</code> box.
</li>
<li>
Click on the <code>Stepwise</code> button.
</li>
<li>
In the Stepwise Options dialog, set the <code>Direction</code> to <code>Mixed</code> (for both forward and backward steps).
</li>
<li>
Specify the stopping criterion (e.g., p-value threshold) and click <code>OK</code>.
</li>
<li>
Click <code>Run</code> to perform the stepwise selection.
</li>
</ul>
</details>
<details>
<summary>
R Code Example:
</summary>
<ul>
<li>
<pre>        # Stepwise Selection in R
        library(MASS)
        
        # Full model
        full_model &lt;- lm(`Minimum Price ($1000)` ~ `Maximum Horsepower` + `Fuel Tank Capacity`+ `Passenger Capacity`, data = cars1993)
        
        # Stepwise selection
        step_model &lt;- stepAIC(full_model, direction = "both")
        
        summary(step_model)
      </pre>
</li>
</ul>
</details>
<details>
<summary>
Python Code Example:
</summary>
<ul>
<li>
<pre>      
 # Stepwise Selection in Python
import pandas as pd
import statsmodels.api as sm
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split

# Load Iris data
iris = load_iris()
X = pd.DataFrame(iris.data, columns=iris.feature_names)
y = iris.target

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)

# Add the target variable to the training data
train_data = X_train.copy()
train_data['target'] = y_train

# Stepwise selection
def stepwise_selected(data, response):
    def calculate_aic(model):
        return sm.OLS(data[response], model).fit().aic

    predictors = list(data.columns)
    predictors.remove(response)
    selected = []
    aic_current = float('inf')
    while predictors:
        aic_with_candidates = []
        for candidate in predictors:
            model = sm.add_constant(data[selected + [candidate]])
            aic = calculate_aic(model)
            aic_with_candidates.append((aic, candidate))
        aic_with_candidates.sort()
        best_aic, best_candidate = aic_with_candidates[0]
        if aic_current &gt; best_aic:
            predictors.remove(best_candidate)
            selected.append(best_candidate)
            aic_current = best_aic
        else:
            break

        # Check if there are selected features before attempting to remove any
        if selected:
            remaining = list(set(data.columns) - set(selected) - {response})
            for candidate in remaining:
                # Check if the candidate is still in the selected list
                if candidate in selected: 
                    model = sm.add_constant(data[selected].drop([candidate], axis=1))
                    aic = calculate_aic(model)
                    if aic &lt; aic_current:
                        selected.remove(candidate)
                        aic_current = aic

    final_model = sm.OLS(data[response], sm.add_constant(data[selected])).fit()
    return final_model

# Apply stepwise selection to Iris dataset
selected_model = stepwise_selected(train_data, 'target')
print(selected_model.summary())
      </pre>
</li>
</ul>
</details>
<details>
<summary>
STATA Code Example:
</summary>
<ul>
<li>
<pre>        // Stepwise Selection in STATA
        stepwise, pr(0.05): regress recovery_time age severity treatment gender comorbidities
      </pre>
</li>
</ul>
</details>
</section>
<section id="lasso" class="level3">
<h3 class="anchored" data-anchor-id="lasso">Lasso</h3>
<details>
<summary>
JMP Instructions:
</summary>
<ul>
<li>
Go to <code>Analyze</code> &gt; <code>Fit Model</code>.
</li>
<li>
Select your dependent variable and move it to the <code>Y</code> box.
</li>
<li>
Select your independent variables and move them to the <code>Construct Model Effects</code> box.
</li>
<li>
Click on the <code>Personality</code> dropdown and select <code>Lasso</code>.
</li>
<li>
Specify the tuning parameter (lambda) or use cross-validation to select it.
</li>
<li>
Click <code>Run</code> to fit the lasso model.
</li>
</ul>
</details>
<details>
<summary>
R Code Example:
</summary>
<ul>
<li>
<pre>       # Install glmnet package if not already installed
install.packages("glmnet")

# Lasso in R
library(glmnet)
        
# Prepare data
  data_2&lt;-read.csv("Cars 1993.csv")
X &lt;- model.matrix(`Minimum.Price...1000.` ~ `Maximum.Horsepower` + `Fuel.Tank.Capacity` + `Passenger.Capacity`, data = data_2)[, -1]
y &lt;- data_2$`Minimum.Price...1000.`
        
#Fit LASSO using cross-validation
set.seed(123) #For reproducibility
cv_fit &lt;- cv.glmnet(X, y, alpha = 1)

#Plot the cross-validation
plot(cv_fit)

#Extract the coefficients of the best model
best_lambda &lt;- cv_fit$lambda.min
lasso_coefficients &lt;- coef(cv_fit, s = "lambda.min")
print(lasso_coefficients)

      </pre>
</li>
</ul>
</details>
<details>
<summary>
Python Code Example:
</summary>
<ul>
<li>
<pre>        
        
        # Lasso in Python
       import pandas as pd
import numpy as np
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.linear_model import Lasso

# Load Iris data
iris = load_iris()
X = pd.DataFrame(iris.data, columns=iris.feature_names)
y = iris.target

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)

# Perform LASSO with cross-validation to find the best alpha
lasso = Lasso(max_iter=10000)
param_grid = {'alpha': np.logspace(-4, 0, 100)}  # Test alpha values from 0.0001 to 1
lasso_cv = GridSearchCV(lasso, param_grid, cv=5)
lasso_cv.fit(X_train, y_train)

# Get the best alpha value and the corresponding model
best_alpha = lasso_cv.best_params_['alpha']
best_model = lasso_cv.best_estimator_

# Get the selected features based on the best model
selected_features = X_train.columns[best_model.coef_ != 0]

# Print the best alpha value and selected features
print("Best alpha:", best_alpha)
print("Selected features:", selected_features)
      </pre>
</li>
</ul>
</details>
<details>
<summary>
STATA Code Example:
</summary>
<ul>
<li>
<pre>        // Lasso in STATA
        lassoreg recovery_time age severity treatment gender comorbidities
      </pre>
</li>
</ul>
</details>
</section>
<section id="multi-step-hierarchical-regression-1" class="level3">
<h3 class="anchored" data-anchor-id="multi-step-hierarchical-regression-1">Multi-Step (Hierarchical Regression)</h3>
<details>
<summary>
JMP Instructions:
</summary>
<ul>
<li>
Go to <code>Analyze</code> &gt; <code>Fit Model</code>.
</li>
<li>
Select your dependent variable and move it to the <code>Y</code> box.
</li>
<li>
Select the first set of independent variables and move them to the <code>Construct Model Effects</code> box.
</li>
<li>
Click <code>Run</code> to fit the first model.
</li>
<li>
To add more variables, go to <code>Redo</code> &gt; <code>Modeling</code> &gt; <code>Add Predictors</code>.
</li>
<li>
Add the next set of variables and click <code>Run</code> again.
</li>
<li>
Repeat the process until all variables are included, fitting the model in steps.
</li>
</ul>
</details>
<details>
<summary>
R Code Example:
</summary>
<ul>
<li>
<pre>        # Multi-Step (Hierarchical Regression) in R
        # Step 1
        model1&lt;- lm(`Minimum Price ($1000)` ~ `Maximum Horsepower`, data = cars1993)
        
        # Step 2
        model2 &lt;- lm(`Minimum Price ($1000)` ~ `Maximum Horsepower` + `Fuel Tank Capacity`, data = cars1993)
        
        # Step 3
        model3 &lt;- lm(`Minimum Price ($1000)` ~ `Maximum Horsepower` + `Fuel Tank Capacity`+ `Passenger Capacity`, data = cars1993)
        
        # Compare models
        summary(model1)
        summary(model2)
        summary(model3)
        
        #ANOVA of models
        anova(model1, model2, model3)

      </pre>
</li>
</ul>
</details>
<details>
<summary>
Python Code Example:
</summary>
<ul>
<li>
<pre>    
# Multi-Step (Hierarchical Regression) in Python
import pandas as pd
import numpy as np
import statsmodels.api as sm
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error

# Load Iris data
iris = load_iris()
X = pd.DataFrame(iris.data, columns=iris.feature_names)
y = iris.target

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)

# Step 1: Regression on a subset of predictors
predictors_step1 = ['sepal length (cm)', 'sepal width (cm)']
X_train_step1 = sm.add_constant(X_train[predictors_step1])
model_step1 = sm.OLS(y_train, X_train_step1)
results_step1 = model_step1.fit()
y_pred_step1 = results_step1.predict(sm.add_constant(X_test[predictors_step1]))
mse_step1 = mean_squared_error(y_test, y_pred_step1)
print("Model Summary - Step 1:")
print(results_step1.summary())
print("Mean Squared Error - Step 1:", mse_step1)

# Step 2: Regression with additional predictors
predictors_step2 = ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)']
X_train_step2 = sm.add_constant(X_train[predictors_step2])
model_step2 = sm.OLS(y_train, X_train_step2)
results_step2 = model_step2.fit()
y_pred_step2 = results_step2.predict(sm.add_constant(X_test[predictors_step2]))
mse_step2 = mean_squared_error(y_test, y_pred_step2)
print("Model Summary - Step 2:")
print(results_step2.summary())
print("Mean Squared Error - Step 2:", mse_step2)

# Step 3: Regression with all predictors
X_train_step3 = sm.add_constant(X_train)
model_step3 = sm.OLS(y_train, X_train_step3)
results_step3 = model_step3.fit()
y_pred_step3 = results_step3.predict(sm.add_constant(X_test))
mse_step3 = mean_squared_error(y_test, y_pred_step3)
print("Model Summary - Step 3:")
print(results_step3.summary())
print("Mean Squared Error - Step 3:", mse_step3)


# COMPARING MSE
print("Mean Squared Error - Step 1:", mse_step1)
print("Mean Squared Error - Step 2:", mse_step2)
print("Mean Squared Error - Step 3:", mse_step3)
      </pre>
</li>
</ul>
</details>
<details>
<summary>
STATA Code Example:
</summary>
<ul>
<li>
<pre>        // Multi-Step (Hierarchical Regression) in STATA
        // Step 1
        regress recovery_time age gender
        
        // Step 2
        regress recovery_time age gender severity
        
        // Step 3
        regress recovery_time age gender severity treatment comorbidities
      </pre>
</li>
</ul>
</details>


<!-- -->

</section>
</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  const viewSource = window.document.getElementById('quarto-view-source') ||
                     window.document.getElementById('quarto-code-tools-source');
  if (viewSource) {
    const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
    viewSource.addEventListener("click", function(e) {
      if (sourceUrl) {
        // rstudio viewer pane
        if (/\bcapabilities=\b/.test(window.location)) {
          window.open(sourceUrl);
        } else {
          window.location.href = sourceUrl;
        }
      } else {
        const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
        modal.show();
      }
      return false;
    });
  }
  function toggleCodeHandler(show) {
    return function(e) {
      const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
      for (let i=0; i<detailsSrc.length; i++) {
        const details = detailsSrc[i].parentElement;
        if (show) {
          details.open = true;
        } else {
          details.removeAttribute("open");
        }
      }
      const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
      const fromCls = show ? "hidden" : "unhidden";
      const toCls = show ? "unhidden" : "hidden";
      for (let i=0; i<cellCodeDivs.length; i++) {
        const codeDiv = cellCodeDivs[i];
        if (codeDiv.classList.contains(fromCls)) {
          codeDiv.classList.remove(fromCls);
          codeDiv.classList.add(toCls);
        } 
      }
      return false;
    }
  }
  const hideAllCode = window.document.getElementById("quarto-hide-all-code");
  if (hideAllCode) {
    hideAllCode.addEventListener("click", toggleCodeHandler(false));
  }
  const showAllCode = window.document.getElementById("quarto-show-all-code");
  if (showAllCode) {
    showAllCode.addEventListener("click", toggleCodeHandler(true));
  }
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="sourceCode" id="cb1" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="an">title:</span><span class="co"> "Model Building and Advanced Linear and Logistic Regression"</span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="an">author:</span><span class="co"> "Dr. Joshua Lambert"</span></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="an">output:</span><span class="co"> html</span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="an">format:</span></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="co">  html:</span></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="co">    toc: true</span></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="co">    toc-title: "Table of Contents"</span></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="co">    code-fold: true</span></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="co">    code-tools: true </span></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="co">    css: styles.css</span></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a><span class="fu"># Model Building and Advanced Linear and Logistic Regression</span></span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a>Understanding the fundamentals and advanced topics of multiple linear and logistic regression analysis is crucial for nursing research. This page will cover the definitions, key concepts, assumptions, and techniques required to build robust models in these contexts.</span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a><span class="fu">## Definition and Purpose of Multiple Linear and Logistic Regression Analysis</span></span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a><span class="fu">### Multiple Linear Regression</span></span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**Definition**: A statistical technique that models the relationship between a dependent variable and two or more independent variables by fitting a linear equation.</span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**Purpose**: To predict the value of the dependent variable based on the values of the independent variables and to understand the relationship between them.</span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a><span class="fu">### Logistic Regression</span></span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**Definition**: A regression model where the dependent variable is categorical, typically binary.</span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**Purpose**: To model the probability of a binary outcome based on one or more predictor variables.</span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-30"><a href="#cb1-30" aria-hidden="true" tabindex="-1"></a><span class="fu">## Key Assumptions and Limitations</span></span>
<span id="cb1-31"><a href="#cb1-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-32"><a href="#cb1-32" aria-hidden="true" tabindex="-1"></a><span class="fu">### Multiple Linear Regression Assumptions</span></span>
<span id="cb1-33"><a href="#cb1-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-34"><a href="#cb1-34" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**Linearity**: The relationship between the dependent and independent variables should be linear.</span>
<span id="cb1-35"><a href="#cb1-35" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**Independence**: Observations should be independent of each other.</span>
<span id="cb1-36"><a href="#cb1-36" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**Homoscedasticity**: The variance of error terms should be constant across all levels of the independent variables.</span>
<span id="cb1-37"><a href="#cb1-37" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**Normality**: The residuals (errors) should be approximately normally distributed.</span>
<span id="cb1-38"><a href="#cb1-38" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**Absence of Multicollinearity**: Predictors should not be too highly correlated with each other.</span>
<span id="cb1-39"><a href="#cb1-39" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**Independence**: Observations should be independent.</span>
<span id="cb1-40"><a href="#cb1-40" aria-hidden="true" tabindex="-1"></a><span class="fu">### Logistic Regression Assumptions</span></span>
<span id="cb1-41"><a href="#cb1-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-42"><a href="#cb1-42" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**Linearity of Logit**: The logit of the outcome should have a linear relationship with the predictor variables.</span>
<span id="cb1-43"><a href="#cb1-43" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**Independence**: Observations should be independent.</span>
<span id="cb1-44"><a href="#cb1-44" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**Absence of Multicollinearity**: Predictors should not be too highly correlated with each other.</span>
<span id="cb1-45"><a href="#cb1-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-46"><a href="#cb1-46" aria-hidden="true" tabindex="-1"></a><span class="fu">## Dependent Variable</span></span>
<span id="cb1-47"><a href="#cb1-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-48"><a href="#cb1-48" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**Multiple Linear Regression**: A continuous variable (e.g., blood pressure, cholesterol level).</span>
<span id="cb1-49"><a href="#cb1-49" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**Logistic Regression**: A categorical variable (e.g., presence or absence of a disease).</span>
<span id="cb1-50"><a href="#cb1-50" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-51"><a href="#cb1-51" aria-hidden="true" tabindex="-1"></a><span class="fu">## Independent Variables</span></span>
<span id="cb1-52"><a href="#cb1-52" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-53"><a href="#cb1-53" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**Definition**: Variables that predict or explain the dependent variable. Can be continuous or categorical.</span>
<span id="cb1-54"><a href="#cb1-54" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**Examples in Nursing Research**: Age, weight, treatment type, comorbidities.</span>
<span id="cb1-55"><a href="#cb1-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-56"><a href="#cb1-56" aria-hidden="true" tabindex="-1"></a><span class="fu">## Variable Selection Techniques</span></span>
<span id="cb1-57"><a href="#cb1-57" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-58"><a href="#cb1-58" aria-hidden="true" tabindex="-1"></a><span class="fu">### Forward Selection</span></span>
<span id="cb1-59"><a href="#cb1-59" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-60"><a href="#cb1-60" aria-hidden="true" tabindex="-1"></a><span class="al">![](https://quantifyinghealth.com/wp-content/uploads/2019/10/forward-stepwise-algorithm.png)</span></span>
<span id="cb1-61"><a href="#cb1-61" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-62"><a href="#cb1-62" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**Method**: Starts with no predictors and adds them one by one based on a specified criterion (e.g., p-value).</span>
<span id="cb1-63"><a href="#cb1-63" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**Process**:</span>
<span id="cb1-64"><a href="#cb1-64" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>Begin with an empty model.</span>
<span id="cb1-65"><a href="#cb1-65" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>Add the predictor with the best criterion (e.g. lowest p-value).</span>
<span id="cb1-66"><a href="#cb1-66" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>Continue adding predictors one at a time, based on criterion, until no additional predictors meet the criterion.</span>
<span id="cb1-67"><a href="#cb1-67" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**Advantages**: Simple and easy to understand.</span>
<span id="cb1-68"><a href="#cb1-68" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**Disadvantages**: Can miss important variables that only show their effect in combination with others. Using p-values to add variables can lead to incorrect model specification. Other methods like AIC, or BIC can perform better.</span>
<span id="cb1-69"><a href="#cb1-69" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-70"><a href="#cb1-70" aria-hidden="true" tabindex="-1"></a><span class="fu">### Backward Selection</span></span>
<span id="cb1-71"><a href="#cb1-71" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-72"><a href="#cb1-72" aria-hidden="true" tabindex="-1"></a><span class="al">![](https://quantifyinghealth.com/wp-content/uploads/2019/10/backward-stepwise-algorithm.png)</span></span>
<span id="cb1-73"><a href="#cb1-73" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-74"><a href="#cb1-74" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**Method**: Starts with all candidate predictors and removes them one by one based on a specified criterion.</span>
<span id="cb1-75"><a href="#cb1-75" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**Process**:</span>
<span id="cb1-76"><a href="#cb1-76" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>Begin with the full model.</span>
<span id="cb1-77"><a href="#cb1-77" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>Remove the predictor with the worst criterion.</span>
<span id="cb1-78"><a href="#cb1-78" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>Continue removing predictors until all remaining predictors meet criterion.</span>
<span id="cb1-79"><a href="#cb1-79" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**Advantages**: Considers the full model from the start.</span>
<span id="cb1-80"><a href="#cb1-80" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**Disadvantages**: Computationally intensive for large set of candidate predictors.</span>
<span id="cb1-81"><a href="#cb1-81" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-82"><a href="#cb1-82" aria-hidden="true" tabindex="-1"></a><span class="fu">### Stepwise Selection</span></span>
<span id="cb1-83"><a href="#cb1-83" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-84"><a href="#cb1-84" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**Method**: A combination of forward and backward selection.</span>
<span id="cb1-85"><a href="#cb1-85" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**Process**:</span>
<span id="cb1-86"><a href="#cb1-86" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>Begin with an empty model or a model with a subset of predictors.</span>
<span id="cb1-87"><a href="#cb1-87" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>Add predictors based on criterion and remove predictors whose criterion no longer meets standard.</span>
<span id="cb1-88"><a href="#cb1-88" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>Continue until no predictors can be added or removed.</span>
<span id="cb1-89"><a href="#cb1-89" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**Advantages**: More flexible and can result in a better model.</span>
<span id="cb1-90"><a href="#cb1-90" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**Disadvantages**: Prone to overfitting and can be unstable.</span>
<span id="cb1-91"><a href="#cb1-91" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-92"><a href="#cb1-92" aria-hidden="true" tabindex="-1"></a><span class="fu">### Lasso (Least Absolute Shrinkage and Selection Operator)</span></span>
<span id="cb1-93"><a href="#cb1-93" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-94"><a href="#cb1-94" aria-hidden="true" tabindex="-1"></a><span class="al">![](https://statmodeling.stat.columbia.edu/wp-content/uploads/2013/03/Screen-Shot-2013-03-17-at-10.43.11-PM.png)</span></span>
<span id="cb1-95"><a href="#cb1-95" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-96"><a href="#cb1-96" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**Method**: Performs both variable selection and regularization to enhance the prediction accuracy and interpretability.</span>
<span id="cb1-97"><a href="#cb1-97" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**Process**:</span>
<span id="cb1-98"><a href="#cb1-98" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>Adds a penalty to the size of the coefficients, shrinking some to zero and thus performing variable selection.</span>
<span id="cb1-99"><a href="#cb1-99" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>The amount of shrinkage is controlled by a tuning parameter (lambda).</span>
<span id="cb1-100"><a href="#cb1-100" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**Advantages**: Can handle large sets of predictors and reduces overfitting.</span>
<span id="cb1-101"><a href="#cb1-101" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**Disadvantages**: Requires careful selection of the regularization parameter. Use cross validation to select.</span>
<span id="cb1-102"><a href="#cb1-102" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-103"><a href="#cb1-103" aria-hidden="true" tabindex="-1"></a><span class="fu">### Multi-Step (Hierarchical Regression)</span></span>
<span id="cb1-104"><a href="#cb1-104" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-105"><a href="#cb1-105" aria-hidden="true" tabindex="-1"></a><span class="al">![](https://www.researchgate.net/publication/287965810/figure/tbl1/AS:647170898284545@1531308974339/Hierarchical-regression-analysis-table.png)</span></span>
<span id="cb1-106"><a href="#cb1-106" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-107"><a href="#cb1-107" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**Method**: Involves entering predictors into the regression model in steps based on theoretical justification.</span>
<span id="cb1-108"><a href="#cb1-108" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**Process**:</span>
<span id="cb1-109"><a href="#cb1-109" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>Enter variables in a pre-specified order, typically based on theoretical importance.</span>
<span id="cb1-110"><a href="#cb1-110" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>Assess the contribution of each variable or set of variables at each step.</span>
<span id="cb1-111"><a href="#cb1-111" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**Advantages**: Allows testing the incremental value of adding new predictors.</span>
<span id="cb1-112"><a href="#cb1-112" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**Disadvantages**: Can be complex to implement and interpret.</span>
<span id="cb1-113"><a href="#cb1-113" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**Confusion with Hierarchical Models**:</span>
<span id="cb1-114"><a href="#cb1-114" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>Hierarchical *regression* involves adding variables in steps to assess their incremental value.</span>
<span id="cb1-115"><a href="#cb1-115" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>Hierarchical *models* (also known as multilevel models) account for data that is nested within higher-level units (e.g., patients within hospitals).</span>
<span id="cb1-116"><a href="#cb1-116" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>Despite similar names, hierarchical regression and hierarchical models address different analytical needs.</span>
<span id="cb1-117"><a href="#cb1-117" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-118"><a href="#cb1-118" aria-hidden="true" tabindex="-1"></a><span class="fu">## Understanding Coefficients</span></span>
<span id="cb1-119"><a href="#cb1-119" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-120"><a href="#cb1-120" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**Interpretation**: Coefficients represent the change in the dependent variable for a one-unit change in the predictor variable, holding other variables constant.</span>
<span id="cb1-121"><a href="#cb1-121" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**Logistic Regression**: Coefficients are in terms of the log odds of the outcome. Once exponentiated, the coefficientsare in terms of change in odds of outcome.</span>
<span id="cb1-122"><a href="#cb1-122" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-123"><a href="#cb1-123" aria-hidden="true" tabindex="-1"></a><span class="fu">## Significance and Confidence Intervals</span></span>
<span id="cb1-124"><a href="#cb1-124" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-125"><a href="#cb1-125" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**P-Values**: Indicate whether there is statistical evidence that the population parameter is significantly different from zero.</span>
<span id="cb1-126"><a href="#cb1-126" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**Confidence Intervals**: Provide a range of values within which the true population parameter is expected to fall. Based on a defined confidence level (e.g. 95%)</span>
<span id="cb1-127"><a href="#cb1-127" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-128"><a href="#cb1-128" aria-hidden="true" tabindex="-1"></a><span class="fu">## Common Criterion: R-Squared and Adjusted R-Squared, and Other Model Fit Statistics</span></span>
<span id="cb1-129"><a href="#cb1-129" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-130"><a href="#cb1-130" aria-hidden="true" tabindex="-1"></a><span class="fu">### Multiple Linear Regression</span></span>
<span id="cb1-131"><a href="#cb1-131" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-132"><a href="#cb1-132" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**R-Squared**: Measures the proportion of variability in the dependent variable that is explained by the independent variables. Problem is that as the number of variables increase the R-Squared will always increase.</span>
<span id="cb1-133"><a href="#cb1-133" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**Adjusted R-Squared**: Adjusts R-squared for the number of predictors in the model. Addresses problem previously mentioned.</span>
<span id="cb1-134"><a href="#cb1-134" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**AIC/BIC (Akaike Information Criterion/Bayesian Information Criterion)**: Used for model comparison, with lower values indicating a better fit and quality.</span>
<span id="cb1-135"><a href="#cb1-135" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-136"><a href="#cb1-136" aria-hidden="true" tabindex="-1"></a><span class="fu">### Logistic Regression</span></span>
<span id="cb1-137"><a href="#cb1-137" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-138"><a href="#cb1-138" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**Pseudo R-Squared**: Analogous to R-squared in linear regression, but measures the goodness of fit for logistic models. Problem is that as the number of variables increase the R-Squared will always increase. Adjusted Pseudo R-Squared do exist.</span>
<span id="cb1-139"><a href="#cb1-139" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**AIC/BIC (Akaike Information Criterion/Bayesian Information Criterion)**: Used for model comparison, with lower values indicating a better fit and quality.</span>
<span id="cb1-140"><a href="#cb1-140" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-141"><a href="#cb1-141" aria-hidden="true" tabindex="-1"></a><span class="fu">## Residual Analysis</span></span>
<span id="cb1-142"><a href="#cb1-142" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-143"><a href="#cb1-143" aria-hidden="true" tabindex="-1"></a><span class="fu">### Normality of Residuals</span></span>
<span id="cb1-144"><a href="#cb1-144" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-145"><a href="#cb1-145" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**Importance**: Ensures the validity of hypothesis tests and confidence intervals.</span>
<span id="cb1-146"><a href="#cb1-146" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**Assessment**: Histogram, Q-Q plot.</span>
<span id="cb1-147"><a href="#cb1-147" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-148"><a href="#cb1-148" aria-hidden="true" tabindex="-1"></a><span class="fu">### Homoscedasticity</span></span>
<span id="cb1-149"><a href="#cb1-149" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-150"><a href="#cb1-150" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**Importance**: Ensures that the residuals have constant variance, which is an assumption of linear regression.</span>
<span id="cb1-151"><a href="#cb1-151" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**Assessment**: Residuals vs. fitted values plot.</span>
<span id="cb1-152"><a href="#cb1-152" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-153"><a href="#cb1-153" aria-hidden="true" tabindex="-1"></a><span class="fu">## Diagnostic Plots</span></span>
<span id="cb1-154"><a href="#cb1-154" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-155"><a href="#cb1-155" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**Residual Plots**: Help assess the assumptions of linearity, homoscedasticity, and independence.</span>
<span id="cb1-156"><a href="#cb1-156" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**Influence Plots**: Identify influential data points that can disproportionately affect the model.</span>
<span id="cb1-157"><a href="#cb1-157" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-158"><a href="#cb1-158" aria-hidden="true" tabindex="-1"></a><span class="fu">## Examples of Model Building in Multiple Linear and Logistic Regression</span></span>
<span id="cb1-159"><a href="#cb1-159" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-160"><a href="#cb1-160" aria-hidden="true" tabindex="-1"></a><span class="fu">### Multiple Linear Regression Example</span></span>
<span id="cb1-161"><a href="#cb1-161" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-162"><a href="#cb1-162" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**Scenario**: Predicting calories of common breakfast cereal based on nutritional information.</span>
<span id="cb1-163"><a href="#cb1-163" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Use the <span class="kw">&lt;a</span> <span class="er">href</span><span class="ot">=</span><span class="st">"Cereal.csv"</span> <span class="er">download</span><span class="kw">&gt;</span>Cereal datatset to run the multiple linear regression.<span class="kw">&lt;/a&gt;</span></span>
<span id="cb1-164"><a href="#cb1-164" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-165"><a href="#cb1-165" aria-hidden="true" tabindex="-1"></a><span class="fu">### Logistic Regression Example</span></span>
<span id="cb1-166"><a href="#cb1-166" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-167"><a href="#cb1-167" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**Scenario**: Predicting the likelihood of domestic vehicle manufacture based on vehicle characteristics.</span>
<span id="cb1-168"><a href="#cb1-168" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Use the <span class="kw">&lt;a</span> <span class="er">href</span><span class="ot">=</span><span class="st">"Cars 1993.csv"</span> <span class="er">download</span><span class="kw">&gt;</span> Cars 1993.csv<span class="kw">&lt;/a&gt;</span> dataset to run the logistic regression. This dataset contains information on 93 cars from the year 1993.</span>
<span id="cb1-169"><a href="#cb1-169" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-170"><a href="#cb1-170" aria-hidden="true" tabindex="-1"></a><span class="fu">## Software Examples</span></span>
<span id="cb1-171"><a href="#cb1-171" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-172"><a href="#cb1-172" aria-hidden="true" tabindex="-1"></a><span class="fu">### Forward Selection</span></span>
<span id="cb1-173"><a href="#cb1-173" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-174"><a href="#cb1-174" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;details&gt;</span></span>
<span id="cb1-175"><a href="#cb1-175" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-176"><a href="#cb1-176" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;summary&gt;</span>JMP Instructions:<span class="kw">&lt;/summary&gt;</span></span>
<span id="cb1-177"><a href="#cb1-177" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-178"><a href="#cb1-178" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;ul&gt;</span></span>
<span id="cb1-179"><a href="#cb1-179" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-180"><a href="#cb1-180" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;li&gt;</span>Go to <span class="kw">&lt;code&gt;</span>Analyze<span class="kw">&lt;/code&gt;</span> <span class="sc">\&gt;</span> <span class="kw">&lt;code&gt;</span>Fit Model<span class="kw">&lt;/code&gt;</span>.<span class="kw">&lt;/li&gt;</span></span>
<span id="cb1-181"><a href="#cb1-181" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-182"><a href="#cb1-182" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;li&gt;</span>Select your dependent variable and move it to the <span class="kw">&lt;code&gt;</span>Y<span class="kw">&lt;/code&gt;</span> box.<span class="kw">&lt;/li&gt;</span></span>
<span id="cb1-183"><a href="#cb1-183" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-184"><a href="#cb1-184" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;li&gt;</span>Select your independent variables and move them to the <span class="kw">&lt;code&gt;</span>Construct Model Effects<span class="kw">&lt;/code&gt;</span> box.<span class="kw">&lt;/li&gt;</span></span>
<span id="cb1-185"><a href="#cb1-185" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-186"><a href="#cb1-186" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;li&gt;</span>Click on the <span class="kw">&lt;code&gt;</span>Stepwise<span class="kw">&lt;/code&gt;</span> button.<span class="kw">&lt;/li&gt;</span></span>
<span id="cb1-187"><a href="#cb1-187" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-188"><a href="#cb1-188" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;li&gt;</span>In the Stepwise Options dialog, set the <span class="kw">&lt;code&gt;</span>Direction<span class="kw">&lt;/code&gt;</span> to <span class="kw">&lt;code&gt;</span>Forward<span class="kw">&lt;/code&gt;</span>.<span class="kw">&lt;/li&gt;</span></span>
<span id="cb1-189"><a href="#cb1-189" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-190"><a href="#cb1-190" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;li&gt;</span>Specify the stopping criterion (e.g., p-value threshold.<span class="kw">&lt;/li&gt;</span></span>
<span id="cb1-191"><a href="#cb1-191" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-192"><a href="#cb1-192" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;li&gt;</span>Click <span class="kw">&lt;code&gt;</span>Run Model<span class="kw">&lt;/code&gt;</span> to perform the forward selection.<span class="kw">&lt;/li&gt;</span></span>
<span id="cb1-193"><a href="#cb1-193" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-194"><a href="#cb1-194" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/ul&gt;</span></span>
<span id="cb1-195"><a href="#cb1-195" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-196"><a href="#cb1-196" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/details&gt;</span></span>
<span id="cb1-197"><a href="#cb1-197" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-198"><a href="#cb1-198" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;details&gt;</span></span>
<span id="cb1-199"><a href="#cb1-199" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-200"><a href="#cb1-200" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;summary&gt;</span>R Code Example:<span class="kw">&lt;/summary&gt;</span></span>
<span id="cb1-201"><a href="#cb1-201" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-202"><a href="#cb1-202" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;ul&gt;</span></span>
<span id="cb1-203"><a href="#cb1-203" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-204"><a href="#cb1-204" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;li&gt;</span></span>
<span id="cb1-205"><a href="#cb1-205" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-206"><a href="#cb1-206" aria-hidden="true" tabindex="-1"></a><span class="in">```{=html}</span></span>
<span id="cb1-207"><a href="#cb1-207" aria-hidden="true" tabindex="-1"></a><span class="in">&lt;pre&gt;</span></span>
<span id="cb1-208"><a href="#cb1-208" aria-hidden="true" tabindex="-1"></a><span class="in">        #Forward selection for MLR</span></span>
<span id="cb1-209"><a href="#cb1-209" aria-hidden="true" tabindex="-1"></a><span class="in"># Load necessary libraries</span></span>
<span id="cb1-210"><a href="#cb1-210" aria-hidden="true" tabindex="-1"></a><span class="in">library(MASS)  </span></span>
<span id="cb1-211"><a href="#cb1-211" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-212"><a href="#cb1-212" aria-hidden="true" tabindex="-1"></a><span class="in"># Load dataset</span></span>
<span id="cb1-213"><a href="#cb1-213" aria-hidden="true" tabindex="-1"></a><span class="in">cars1993&lt;-read_csv("Cars 1993.csv")</span></span>
<span id="cb1-214"><a href="#cb1-214" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-215"><a href="#cb1-215" aria-hidden="true" tabindex="-1"></a><span class="in">#Build the full model</span></span>
<span id="cb1-216"><a href="#cb1-216" aria-hidden="true" tabindex="-1"></a><span class="in">full_model &lt;- lm(`Minimum Price ($1000)` ~ `Maximum Horsepower` + `Fuel Tank Capacity`+ `Passenger Capacity`, data = cars1993)</span></span>
<span id="cb1-217"><a href="#cb1-217" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-218"><a href="#cb1-218" aria-hidden="true" tabindex="-1"></a><span class="in"># Forward stepwise selection</span></span>
<span id="cb1-219"><a href="#cb1-219" aria-hidden="true" tabindex="-1"></a><span class="in">step_model &lt;- stepAIC(lm(`Minimum Price ($1000)` ~ 1, data = cars1993), </span></span>
<span id="cb1-220"><a href="#cb1-220" aria-hidden="true" tabindex="-1"></a><span class="in">                      direction = "forward", </span></span>
<span id="cb1-221"><a href="#cb1-221" aria-hidden="true" tabindex="-1"></a><span class="in">                      scope = list(lower = ~1, upper = full_model))</span></span>
<span id="cb1-222"><a href="#cb1-222" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-223"><a href="#cb1-223" aria-hidden="true" tabindex="-1"></a><span class="in"># Print summary of the final model selected by forward selection</span></span>
<span id="cb1-224"><a href="#cb1-224" aria-hidden="true" tabindex="-1"></a><span class="in">summary(step_model)</span></span>
<span id="cb1-225"><a href="#cb1-225" aria-hidden="true" tabindex="-1"></a><span class="in">      &lt;/pre&gt;</span></span>
<span id="cb1-226"><a href="#cb1-226" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb1-227"><a href="#cb1-227" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/li&gt;</span></span>
<span id="cb1-228"><a href="#cb1-228" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-229"><a href="#cb1-229" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/ul&gt;</span></span>
<span id="cb1-230"><a href="#cb1-230" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-231"><a href="#cb1-231" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/details&gt;</span></span>
<span id="cb1-232"><a href="#cb1-232" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-233"><a href="#cb1-233" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;details&gt;</span></span>
<span id="cb1-234"><a href="#cb1-234" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-235"><a href="#cb1-235" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;summary&gt;</span>Python Code Example:<span class="kw">&lt;/summary&gt;</span></span>
<span id="cb1-236"><a href="#cb1-236" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-237"><a href="#cb1-237" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;ul&gt;</span></span>
<span id="cb1-238"><a href="#cb1-238" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-239"><a href="#cb1-239" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;li&gt;</span></span>
<span id="cb1-240"><a href="#cb1-240" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-241"><a href="#cb1-241" aria-hidden="true" tabindex="-1"></a><span class="in">```{=html}</span></span>
<span id="cb1-242"><a href="#cb1-242" aria-hidden="true" tabindex="-1"></a><span class="in">&lt;pre&gt;</span></span>
<span id="cb1-243"><a href="#cb1-243" aria-hidden="true" tabindex="-1"></a><span class="in">import pandas as pd</span></span>
<span id="cb1-244"><a href="#cb1-244" aria-hidden="true" tabindex="-1"></a><span class="in">from sklearn.model_selection import train_test_split</span></span>
<span id="cb1-245"><a href="#cb1-245" aria-hidden="true" tabindex="-1"></a><span class="in">from sklearn.datasets import load_iris</span></span>
<span id="cb1-246"><a href="#cb1-246" aria-hidden="true" tabindex="-1"></a><span class="in">from sklearn.ensemble import RandomForestClassifier</span></span>
<span id="cb1-247"><a href="#cb1-247" aria-hidden="true" tabindex="-1"></a><span class="in">from sklearn.feature_selection import SelectFromModel</span></span>
<span id="cb1-248"><a href="#cb1-248" aria-hidden="true" tabindex="-1"></a><span class="in">from sklearn.linear_model import LinearRegression</span></span>
<span id="cb1-249"><a href="#cb1-249" aria-hidden="true" tabindex="-1"></a><span class="in">import numpy as np</span></span>
<span id="cb1-250"><a href="#cb1-250" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-251"><a href="#cb1-251" aria-hidden="true" tabindex="-1"></a><span class="in"># Load iris data</span></span>
<span id="cb1-252"><a href="#cb1-252" aria-hidden="true" tabindex="-1"></a><span class="in">iris = load_iris()</span></span>
<span id="cb1-253"><a href="#cb1-253" aria-hidden="true" tabindex="-1"></a><span class="in">X = pd.DataFrame(iris.data, columns=iris.feature_names)</span></span>
<span id="cb1-254"><a href="#cb1-254" aria-hidden="true" tabindex="-1"></a><span class="in">y = iris.target</span></span>
<span id="cb1-255"><a href="#cb1-255" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-256"><a href="#cb1-256" aria-hidden="true" tabindex="-1"></a><span class="in"># Split the data into training and testing sets</span></span>
<span id="cb1-257"><a href="#cb1-257" aria-hidden="true" tabindex="-1"></a><span class="in">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)</span></span>
<span id="cb1-258"><a href="#cb1-258" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-259"><a href="#cb1-259" aria-hidden="true" tabindex="-1"></a><span class="in"># Feature selection using Random Forest</span></span>
<span id="cb1-260"><a href="#cb1-260" aria-hidden="true" tabindex="-1"></a><span class="in">rf = RandomForestClassifier(n_estimators=100, random_state=0)</span></span>
<span id="cb1-261"><a href="#cb1-261" aria-hidden="true" tabindex="-1"></a><span class="in">sfm = SelectFromModel(rf, threshold='median')</span></span>
<span id="cb1-262"><a href="#cb1-262" aria-hidden="true" tabindex="-1"></a><span class="in">X_train_selected = sfm.fit_transform(X_train, y_train)</span></span>
<span id="cb1-263"><a href="#cb1-263" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-264"><a href="#cb1-264" aria-hidden="true" tabindex="-1"></a><span class="in"># Get the selected feature indices</span></span>
<span id="cb1-265"><a href="#cb1-265" aria-hidden="true" tabindex="-1"></a><span class="in">selected_feature_indices = sfm.get_support(indices=True)</span></span>
<span id="cb1-266"><a href="#cb1-266" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-267"><a href="#cb1-267" aria-hidden="true" tabindex="-1"></a><span class="in"># Get the selected feature names</span></span>
<span id="cb1-268"><a href="#cb1-268" aria-hidden="true" tabindex="-1"></a><span class="in">selected_features = X_train.columns[selected_feature_indices]</span></span>
<span id="cb1-269"><a href="#cb1-269" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-270"><a href="#cb1-270" aria-hidden="true" tabindex="-1"></a><span class="in">def forward_selection(X_train, y_train, selected_features):</span></span>
<span id="cb1-271"><a href="#cb1-271" aria-hidden="true" tabindex="-1"></a><span class="in">    remaining_features = set(selected_features)</span></span>
<span id="cb1-272"><a href="#cb1-272" aria-hidden="true" tabindex="-1"></a><span class="in">    current_score = float('inf')</span></span>
<span id="cb1-273"><a href="#cb1-273" aria-hidden="true" tabindex="-1"></a><span class="in">    best_new_score = float('inf')</span></span>
<span id="cb1-274"><a href="#cb1-274" aria-hidden="true" tabindex="-1"></a><span class="in">    selected_features_list = [] # Use a list to store selected feature names</span></span>
<span id="cb1-275"><a href="#cb1-275" aria-hidden="true" tabindex="-1"></a><span class="in">    </span></span>
<span id="cb1-276"><a href="#cb1-276" aria-hidden="true" tabindex="-1"></a><span class="in">    while remaining_features:</span></span>
<span id="cb1-277"><a href="#cb1-277" aria-hidden="true" tabindex="-1"></a><span class="in">        scores_with_candidates = []</span></span>
<span id="cb1-278"><a href="#cb1-278" aria-hidden="true" tabindex="-1"></a><span class="in">        for candidate in remaining_features:</span></span>
<span id="cb1-279"><a href="#cb1-279" aria-hidden="true" tabindex="-1"></a><span class="in">            # Add the candidate feature to the selected features</span></span>
<span id="cb1-280"><a href="#cb1-280" aria-hidden="true" tabindex="-1"></a><span class="in">            selected_features_list.append(candidate)</span></span>
<span id="cb1-281"><a href="#cb1-281" aria-hidden="true" tabindex="-1"></a><span class="in">            </span></span>
<span id="cb1-282"><a href="#cb1-282" aria-hidden="true" tabindex="-1"></a><span class="in">            # Fit a model with the selected features</span></span>
<span id="cb1-283"><a href="#cb1-283" aria-hidden="true" tabindex="-1"></a><span class="in">            # Use the list of selected feature names to index X_train</span></span>
<span id="cb1-284"><a href="#cb1-284" aria-hidden="true" tabindex="-1"></a><span class="in">            model = LinearRegression().fit(X_train[selected_features_list], y_train) </span></span>
<span id="cb1-285"><a href="#cb1-285" aria-hidden="true" tabindex="-1"></a><span class="in">            </span></span>
<span id="cb1-286"><a href="#cb1-286" aria-hidden="true" tabindex="-1"></a><span class="in">            # Calculate the AIC score</span></span>
<span id="cb1-287"><a href="#cb1-287" aria-hidden="true" tabindex="-1"></a><span class="in">            RSS = sum((model.predict(X_train[selected_features_list]) - y_train) ** 2)</span></span>
<span id="cb1-288"><a href="#cb1-288" aria-hidden="true" tabindex="-1"></a><span class="in">            n = len(X_train)</span></span>
<span id="cb1-289"><a href="#cb1-289" aria-hidden="true" tabindex="-1"></a><span class="in">            p = len(selected_features_list)</span></span>
<span id="cb1-290"><a href="#cb1-290" aria-hidden="true" tabindex="-1"></a><span class="in">            score = n * np.log(RSS / n) + 2 * p</span></span>
<span id="cb1-291"><a href="#cb1-291" aria-hidden="true" tabindex="-1"></a><span class="in">            </span></span>
<span id="cb1-292"><a href="#cb1-292" aria-hidden="true" tabindex="-1"></a><span class="in">            # Store the score and the candidate feature</span></span>
<span id="cb1-293"><a href="#cb1-293" aria-hidden="true" tabindex="-1"></a><span class="in">            scores_with_candidates.append((score, candidate))</span></span>
<span id="cb1-294"><a href="#cb1-294" aria-hidden="true" tabindex="-1"></a><span class="in">            </span></span>
<span id="cb1-295"><a href="#cb1-295" aria-hidden="true" tabindex="-1"></a><span class="in">            # Remove the candidate feature from the selected features</span></span>
<span id="cb1-296"><a href="#cb1-296" aria-hidden="true" tabindex="-1"></a><span class="in">            selected_features_list.pop()</span></span>
<span id="cb1-297"><a href="#cb1-297" aria-hidden="true" tabindex="-1"></a><span class="in">        </span></span>
<span id="cb1-298"><a href="#cb1-298" aria-hidden="true" tabindex="-1"></a><span class="in">        # Sort the scores and select the best candidate</span></span>
<span id="cb1-299"><a href="#cb1-299" aria-hidden="true" tabindex="-1"></a><span class="in">        scores_with_candidates.sort()</span></span>
<span id="cb1-300"><a href="#cb1-300" aria-hidden="true" tabindex="-1"></a><span class="in">        best_new_score, best_candidate = scores_with_candidates[0]</span></span>
<span id="cb1-301"><a href="#cb1-301" aria-hidden="true" tabindex="-1"></a><span class="in">        </span></span>
<span id="cb1-302"><a href="#cb1-302" aria-hidden="true" tabindex="-1"></a><span class="in">        # If the new score is better than the current score, update the current score and add the best candidate to the selected features</span></span>
<span id="cb1-303"><a href="#cb1-303" aria-hidden="true" tabindex="-1"></a><span class="in">        if current_score &gt; best_new_score:</span></span>
<span id="cb1-304"><a href="#cb1-304" aria-hidden="true" tabindex="-1"></a><span class="in">            current_score = best_new_score</span></span>
<span id="cb1-305"><a href="#cb1-305" aria-hidden="true" tabindex="-1"></a><span class="in">            selected_features_list.append(best_candidate) # Append to the list</span></span>
<span id="cb1-306"><a href="#cb1-306" aria-hidden="true" tabindex="-1"></a><span class="in">            remaining_features.remove(best_candidate)</span></span>
<span id="cb1-307"><a href="#cb1-307" aria-hidden="true" tabindex="-1"></a><span class="in">    </span></span>
<span id="cb1-308"><a href="#cb1-308" aria-hidden="true" tabindex="-1"></a><span class="in">    # Fit a model with the selected features</span></span>
<span id="cb1-309"><a href="#cb1-309" aria-hidden="true" tabindex="-1"></a><span class="in">    # Index X_train with the list of selected feature names</span></span>
<span id="cb1-310"><a href="#cb1-310" aria-hidden="true" tabindex="-1"></a><span class="in">    model = LinearRegression().fit(X_train[selected_features_list], y_train) </span></span>
<span id="cb1-311"><a href="#cb1-311" aria-hidden="true" tabindex="-1"></a><span class="in">    </span></span>
<span id="cb1-312"><a href="#cb1-312" aria-hidden="true" tabindex="-1"></a><span class="in">    return model, selected_features_list # Return both the model and the list of selected features</span></span>
<span id="cb1-313"><a href="#cb1-313" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-314"><a href="#cb1-314" aria-hidden="true" tabindex="-1"></a><span class="in"># Run forward selection</span></span>
<span id="cb1-315"><a href="#cb1-315" aria-hidden="true" tabindex="-1"></a><span class="in"># Pass the list of selected feature names to the function</span></span>
<span id="cb1-316"><a href="#cb1-316" aria-hidden="true" tabindex="-1"></a><span class="in">model, selected_features_list = forward_selection(X_train, y_train, selected_features) </span></span>
<span id="cb1-317"><a href="#cb1-317" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-318"><a href="#cb1-318" aria-hidden="true" tabindex="-1"></a><span class="in"># Print the summary of the model</span></span>
<span id="cb1-319"><a href="#cb1-319" aria-hidden="true" tabindex="-1"></a><span class="in">print("Selected Features:", model.coef_)</span></span>
<span id="cb1-320"><a href="#cb1-320" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-321"><a href="#cb1-321" aria-hidden="true" tabindex="-1"></a><span class="in"># Print the selected feature column names</span></span>
<span id="cb1-322"><a href="#cb1-322" aria-hidden="true" tabindex="-1"></a><span class="in">print("Selected Features:")</span></span>
<span id="cb1-323"><a href="#cb1-323" aria-hidden="true" tabindex="-1"></a><span class="in">for feature in selected_features_list: # Iterate over the list of selected features</span></span>
<span id="cb1-324"><a href="#cb1-324" aria-hidden="true" tabindex="-1"></a><span class="in">    print(feature)</span></span>
<span id="cb1-325"><a href="#cb1-325" aria-hidden="true" tabindex="-1"></a><span class="in">      &lt;/pre&gt;</span></span>
<span id="cb1-326"><a href="#cb1-326" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb1-327"><a href="#cb1-327" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/li&gt;</span></span>
<span id="cb1-328"><a href="#cb1-328" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-329"><a href="#cb1-329" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/ul&gt;</span></span>
<span id="cb1-330"><a href="#cb1-330" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-331"><a href="#cb1-331" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/details&gt;</span></span>
<span id="cb1-332"><a href="#cb1-332" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-333"><a href="#cb1-333" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;details&gt;</span></span>
<span id="cb1-334"><a href="#cb1-334" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-335"><a href="#cb1-335" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;summary&gt;</span>STATA Code Example:<span class="kw">&lt;/summary&gt;</span></span>
<span id="cb1-336"><a href="#cb1-336" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-337"><a href="#cb1-337" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;ul&gt;</span></span>
<span id="cb1-338"><a href="#cb1-338" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-339"><a href="#cb1-339" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;li&gt;</span></span>
<span id="cb1-340"><a href="#cb1-340" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-341"><a href="#cb1-341" aria-hidden="true" tabindex="-1"></a><span class="in">```{=html}</span></span>
<span id="cb1-342"><a href="#cb1-342" aria-hidden="true" tabindex="-1"></a><span class="in">&lt;pre&gt;</span></span>
<span id="cb1-343"><a href="#cb1-343" aria-hidden="true" tabindex="-1"></a><span class="in">        // Forward Selection in STATA</span></span>
<span id="cb1-344"><a href="#cb1-344" aria-hidden="true" tabindex="-1"></a><span class="in">        stepwise, pr(0.05): regress recovery_time age severity treatment gender comorbidities</span></span>
<span id="cb1-345"><a href="#cb1-345" aria-hidden="true" tabindex="-1"></a><span class="in">      &lt;/pre&gt;</span></span>
<span id="cb1-346"><a href="#cb1-346" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb1-347"><a href="#cb1-347" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/li&gt;</span></span>
<span id="cb1-348"><a href="#cb1-348" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-349"><a href="#cb1-349" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/ul&gt;</span></span>
<span id="cb1-350"><a href="#cb1-350" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-351"><a href="#cb1-351" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/details&gt;</span></span>
<span id="cb1-352"><a href="#cb1-352" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-353"><a href="#cb1-353" aria-hidden="true" tabindex="-1"></a><span class="fu">### Backward Selection</span></span>
<span id="cb1-354"><a href="#cb1-354" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-355"><a href="#cb1-355" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;details&gt;</span></span>
<span id="cb1-356"><a href="#cb1-356" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-357"><a href="#cb1-357" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;summary&gt;</span>JMP Instructions:<span class="kw">&lt;/summary&gt;</span></span>
<span id="cb1-358"><a href="#cb1-358" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-359"><a href="#cb1-359" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;ul&gt;</span></span>
<span id="cb1-360"><a href="#cb1-360" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-361"><a href="#cb1-361" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;li&gt;</span>Go to <span class="kw">&lt;code&gt;</span>Analyze<span class="kw">&lt;/code&gt;</span> <span class="sc">\&gt;</span> <span class="kw">&lt;code&gt;</span>Fit Model<span class="kw">&lt;/code&gt;</span>.<span class="kw">&lt;/li&gt;</span></span>
<span id="cb1-362"><a href="#cb1-362" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-363"><a href="#cb1-363" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;li&gt;</span>Select your dependent variable and move it to the <span class="kw">&lt;code&gt;</span>Y<span class="kw">&lt;/code&gt;</span> box.<span class="kw">&lt;/li&gt;</span></span>
<span id="cb1-364"><a href="#cb1-364" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-365"><a href="#cb1-365" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;li&gt;</span>Select your independent variables and move them to the <span class="kw">&lt;code&gt;</span>Construct Model Effects<span class="kw">&lt;/code&gt;</span> box.<span class="kw">&lt;/li&gt;</span></span>
<span id="cb1-366"><a href="#cb1-366" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-367"><a href="#cb1-367" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;li&gt;</span>Click on the <span class="kw">&lt;code&gt;</span>Stepwise<span class="kw">&lt;/code&gt;</span> button.<span class="kw">&lt;/li&gt;</span></span>
<span id="cb1-368"><a href="#cb1-368" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-369"><a href="#cb1-369" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;li&gt;</span>In the Stepwise Options dialog, set the <span class="kw">&lt;code&gt;</span>Direction<span class="kw">&lt;/code&gt;</span> to <span class="kw">&lt;code&gt;</span>Backward<span class="kw">&lt;/code&gt;</span>.<span class="kw">&lt;/li&gt;</span></span>
<span id="cb1-370"><a href="#cb1-370" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-371"><a href="#cb1-371" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;li&gt;</span>Specify the stopping criterion (e.g., p-value threshold) and click <span class="kw">&lt;code&gt;</span>OK<span class="kw">&lt;/code&gt;</span>.<span class="kw">&lt;/li&gt;</span></span>
<span id="cb1-372"><a href="#cb1-372" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-373"><a href="#cb1-373" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;li&gt;</span>Click <span class="kw">&lt;code&gt;</span>Run<span class="kw">&lt;/code&gt;</span> to perform the backward selection.<span class="kw">&lt;/li&gt;</span></span>
<span id="cb1-374"><a href="#cb1-374" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-375"><a href="#cb1-375" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/ul&gt;</span></span>
<span id="cb1-376"><a href="#cb1-376" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-377"><a href="#cb1-377" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/details&gt;</span></span>
<span id="cb1-378"><a href="#cb1-378" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-379"><a href="#cb1-379" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;details&gt;</span></span>
<span id="cb1-380"><a href="#cb1-380" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-381"><a href="#cb1-381" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;summary&gt;</span>R Code Example:<span class="kw">&lt;/summary&gt;</span></span>
<span id="cb1-382"><a href="#cb1-382" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-383"><a href="#cb1-383" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;ul&gt;</span></span>
<span id="cb1-384"><a href="#cb1-384" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-385"><a href="#cb1-385" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;li&gt;</span></span>
<span id="cb1-386"><a href="#cb1-386" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-387"><a href="#cb1-387" aria-hidden="true" tabindex="-1"></a><span class="in">```{=html}</span></span>
<span id="cb1-388"><a href="#cb1-388" aria-hidden="true" tabindex="-1"></a><span class="in">&lt;pre&gt;</span></span>
<span id="cb1-389"><a href="#cb1-389" aria-hidden="true" tabindex="-1"></a><span class="in">        #Backward selection with MLR</span></span>
<span id="cb1-390"><a href="#cb1-390" aria-hidden="true" tabindex="-1"></a><span class="in"># Load necessary libraries</span></span>
<span id="cb1-391"><a href="#cb1-391" aria-hidden="true" tabindex="-1"></a><span class="in">library(MASS)  </span></span>
<span id="cb1-392"><a href="#cb1-392" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-393"><a href="#cb1-393" aria-hidden="true" tabindex="-1"></a><span class="in"># Load dataset</span></span>
<span id="cb1-394"><a href="#cb1-394" aria-hidden="true" tabindex="-1"></a><span class="in">cars1993&lt;-read_csv("Cars 1993.csv")</span></span>
<span id="cb1-395"><a href="#cb1-395" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-396"><a href="#cb1-396" aria-hidden="true" tabindex="-1"></a><span class="in">#Build the full model</span></span>
<span id="cb1-397"><a href="#cb1-397" aria-hidden="true" tabindex="-1"></a><span class="in">full_model &lt;- lm(`Minimum Price ($1000)` ~ `Maximum Horsepower` + `Fuel Tank Capacity`+ `Passenger Capacity`, data = cars1993)</span></span>
<span id="cb1-398"><a href="#cb1-398" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-399"><a href="#cb1-399" aria-hidden="true" tabindex="-1"></a><span class="in"># Backward stepwise selection</span></span>
<span id="cb1-400"><a href="#cb1-400" aria-hidden="true" tabindex="-1"></a><span class="in">step_model &lt;- stepAIC(full_model, direction = "backward")</span></span>
<span id="cb1-401"><a href="#cb1-401" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-402"><a href="#cb1-402" aria-hidden="true" tabindex="-1"></a><span class="in"># Print summary of the final model selected by backward selection</span></span>
<span id="cb1-403"><a href="#cb1-403" aria-hidden="true" tabindex="-1"></a><span class="in">summary(step_model)</span></span>
<span id="cb1-404"><a href="#cb1-404" aria-hidden="true" tabindex="-1"></a><span class="in">  </span></span>
<span id="cb1-405"><a href="#cb1-405" aria-hidden="true" tabindex="-1"></a><span class="in">      &lt;/pre&gt;</span></span>
<span id="cb1-406"><a href="#cb1-406" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb1-407"><a href="#cb1-407" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/li&gt;</span></span>
<span id="cb1-408"><a href="#cb1-408" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-409"><a href="#cb1-409" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/ul&gt;</span></span>
<span id="cb1-410"><a href="#cb1-410" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-411"><a href="#cb1-411" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/details&gt;</span></span>
<span id="cb1-412"><a href="#cb1-412" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-413"><a href="#cb1-413" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;details&gt;</span></span>
<span id="cb1-414"><a href="#cb1-414" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-415"><a href="#cb1-415" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;summary&gt;</span>Python Code Example:<span class="kw">&lt;/summary&gt;</span></span>
<span id="cb1-416"><a href="#cb1-416" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-417"><a href="#cb1-417" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;ul&gt;</span></span>
<span id="cb1-418"><a href="#cb1-418" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-419"><a href="#cb1-419" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;li&gt;</span></span>
<span id="cb1-420"><a href="#cb1-420" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-421"><a href="#cb1-421" aria-hidden="true" tabindex="-1"></a><span class="in">```{=html}</span></span>
<span id="cb1-422"><a href="#cb1-422" aria-hidden="true" tabindex="-1"></a><span class="in">&lt;pre&gt;</span></span>
<span id="cb1-423"><a href="#cb1-423" aria-hidden="true" tabindex="-1"></a><span class="in">import pandas as pd</span></span>
<span id="cb1-424"><a href="#cb1-424" aria-hidden="true" tabindex="-1"></a><span class="in">from sklearn.model_selection import train_test_split</span></span>
<span id="cb1-425"><a href="#cb1-425" aria-hidden="true" tabindex="-1"></a><span class="in">from sklearn.datasets import load_iris</span></span>
<span id="cb1-426"><a href="#cb1-426" aria-hidden="true" tabindex="-1"></a><span class="in">from sklearn.feature_selection import SelectFromModel</span></span>
<span id="cb1-427"><a href="#cb1-427" aria-hidden="true" tabindex="-1"></a><span class="in">from sklearn.linear_model import LinearRegression</span></span>
<span id="cb1-428"><a href="#cb1-428" aria-hidden="true" tabindex="-1"></a><span class="in">import numpy as np</span></span>
<span id="cb1-429"><a href="#cb1-429" aria-hidden="true" tabindex="-1"></a><span class="in">from sklearn.linear_model import Lasso</span></span>
<span id="cb1-430"><a href="#cb1-430" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-431"><a href="#cb1-431" aria-hidden="true" tabindex="-1"></a><span class="in"># Load iris data</span></span>
<span id="cb1-432"><a href="#cb1-432" aria-hidden="true" tabindex="-1"></a><span class="in">iris = load_iris()</span></span>
<span id="cb1-433"><a href="#cb1-433" aria-hidden="true" tabindex="-1"></a><span class="in">X = pd.DataFrame(iris.data, columns=iris.feature_names)</span></span>
<span id="cb1-434"><a href="#cb1-434" aria-hidden="true" tabindex="-1"></a><span class="in">y = iris.target</span></span>
<span id="cb1-435"><a href="#cb1-435" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-436"><a href="#cb1-436" aria-hidden="true" tabindex="-1"></a><span class="in"># Split the data into training and testing sets</span></span>
<span id="cb1-437"><a href="#cb1-437" aria-hidden="true" tabindex="-1"></a><span class="in">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)</span></span>
<span id="cb1-438"><a href="#cb1-438" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-439"><a href="#cb1-439" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-440"><a href="#cb1-440" aria-hidden="true" tabindex="-1"></a><span class="in">def backward_selection(X_train, y_train):</span></span>
<span id="cb1-441"><a href="#cb1-441" aria-hidden="true" tabindex="-1"></a><span class="in">    remaining_features = set(X_train.columns)</span></span>
<span id="cb1-442"><a href="#cb1-442" aria-hidden="true" tabindex="-1"></a><span class="in">    current_score = float('inf')</span></span>
<span id="cb1-443"><a href="#cb1-443" aria-hidden="true" tabindex="-1"></a><span class="in">    selected_features_list = list(X_train.columns)</span></span>
<span id="cb1-444"><a href="#cb1-444" aria-hidden="true" tabindex="-1"></a><span class="in">    </span></span>
<span id="cb1-445"><a href="#cb1-445" aria-hidden="true" tabindex="-1"></a><span class="in">    # Change the model to Lasso for feature selection</span></span>
<span id="cb1-446"><a href="#cb1-446" aria-hidden="true" tabindex="-1"></a><span class="in">    model = Lasso(alpha=0.01)</span></span>
<span id="cb1-447"><a href="#cb1-447" aria-hidden="true" tabindex="-1"></a><span class="in">    </span></span>
<span id="cb1-448"><a href="#cb1-448" aria-hidden="true" tabindex="-1"></a><span class="in">    while len(remaining_features) &gt; 1:</span></span>
<span id="cb1-449"><a href="#cb1-449" aria-hidden="true" tabindex="-1"></a><span class="in">        scores_with_candidates = []</span></span>
<span id="cb1-450"><a href="#cb1-450" aria-hidden="true" tabindex="-1"></a><span class="in">        for candidate in remaining_features:</span></span>
<span id="cb1-451"><a href="#cb1-451" aria-hidden="true" tabindex="-1"></a><span class="in">            # Temporarily remove the candidate feature from the selected features</span></span>
<span id="cb1-452"><a href="#cb1-452" aria-hidden="true" tabindex="-1"></a><span class="in">            selected_features_list.remove(candidate)</span></span>
<span id="cb1-453"><a href="#cb1-453" aria-hidden="true" tabindex="-1"></a><span class="in">            </span></span>
<span id="cb1-454"><a href="#cb1-454" aria-hidden="true" tabindex="-1"></a><span class="in">            # Fit the Lasso model with the remaining features</span></span>
<span id="cb1-455"><a href="#cb1-455" aria-hidden="true" tabindex="-1"></a><span class="in">            model.fit(X_train[selected_features_list], y_train)</span></span>
<span id="cb1-456"><a href="#cb1-456" aria-hidden="true" tabindex="-1"></a><span class="in">            </span></span>
<span id="cb1-457"><a href="#cb1-457" aria-hidden="true" tabindex="-1"></a><span class="in">            # Calculate the AIC score</span></span>
<span id="cb1-458"><a href="#cb1-458" aria-hidden="true" tabindex="-1"></a><span class="in">            RSS = sum((model.predict(X_train[selected_features_list]) - y_train) ** 2)</span></span>
<span id="cb1-459"><a href="#cb1-459" aria-hidden="true" tabindex="-1"></a><span class="in">            n = len(X_train)</span></span>
<span id="cb1-460"><a href="#cb1-460" aria-hidden="true" tabindex="-1"></a><span class="in">            p = len(selected_features_list)</span></span>
<span id="cb1-461"><a href="#cb1-461" aria-hidden="true" tabindex="-1"></a><span class="in">            score = n * np.log(RSS / n) + 2 * p</span></span>
<span id="cb1-462"><a href="#cb1-462" aria-hidden="true" tabindex="-1"></a><span class="in">            </span></span>
<span id="cb1-463"><a href="#cb1-463" aria-hidden="true" tabindex="-1"></a><span class="in">            # Store the score and the candidate feature</span></span>
<span id="cb1-464"><a href="#cb1-464" aria-hidden="true" tabindex="-1"></a><span class="in">            scores_with_candidates.append((score, candidate))</span></span>
<span id="cb1-465"><a href="#cb1-465" aria-hidden="true" tabindex="-1"></a><span class="in">            </span></span>
<span id="cb1-466"><a href="#cb1-466" aria-hidden="true" tabindex="-1"></a><span class="in">            # Add the candidate feature back to the selected features</span></span>
<span id="cb1-467"><a href="#cb1-467" aria-hidden="true" tabindex="-1"></a><span class="in">            selected_features_list.append(candidate)</span></span>
<span id="cb1-468"><a href="#cb1-468" aria-hidden="true" tabindex="-1"></a><span class="in">        </span></span>
<span id="cb1-469"><a href="#cb1-469" aria-hidden="true" tabindex="-1"></a><span class="in">        # Sort the scores in ascending order</span></span>
<span id="cb1-470"><a href="#cb1-470" aria-hidden="true" tabindex="-1"></a><span class="in">        scores_with_candidates.sort()</span></span>
<span id="cb1-471"><a href="#cb1-471" aria-hidden="true" tabindex="-1"></a><span class="in">        </span></span>
<span id="cb1-472"><a href="#cb1-472" aria-hidden="true" tabindex="-1"></a><span class="in">        # Select the candidate feature with the highest score</span></span>
<span id="cb1-473"><a href="#cb1-473" aria-hidden="true" tabindex="-1"></a><span class="in">        _, worst_candidate = scores_with_candidates.pop(0)</span></span>
<span id="cb1-474"><a href="#cb1-474" aria-hidden="true" tabindex="-1"></a><span class="in">        </span></span>
<span id="cb1-475"><a href="#cb1-475" aria-hidden="true" tabindex="-1"></a><span class="in">        # If removing the worst candidate improves the score, remove it</span></span>
<span id="cb1-476"><a href="#cb1-476" aria-hidden="true" tabindex="-1"></a><span class="in">        if scores_with_candidates[-1][0] &lt; current_score: </span></span>
<span id="cb1-477"><a href="#cb1-477" aria-hidden="true" tabindex="-1"></a><span class="in">            selected_features_list.remove(worst_candidate)</span></span>
<span id="cb1-478"><a href="#cb1-478" aria-hidden="true" tabindex="-1"></a><span class="in">            remaining_features.remove(worst_candidate)</span></span>
<span id="cb1-479"><a href="#cb1-479" aria-hidden="true" tabindex="-1"></a><span class="in">            current_score = scores_with_candidates[-1][0]</span></span>
<span id="cb1-480"><a href="#cb1-480" aria-hidden="true" tabindex="-1"></a><span class="in">        else:</span></span>
<span id="cb1-481"><a href="#cb1-481" aria-hidden="true" tabindex="-1"></a><span class="in">            break  # Early stopping if improvement becomes negligible</span></span>
<span id="cb1-482"><a href="#cb1-482" aria-hidden="true" tabindex="-1"></a><span class="in">    </span></span>
<span id="cb1-483"><a href="#cb1-483" aria-hidden="true" tabindex="-1"></a><span class="in">    # Fit the final Lasso model with the remaining features</span></span>
<span id="cb1-484"><a href="#cb1-484" aria-hidden="true" tabindex="-1"></a><span class="in">    model.fit(X_train[selected_features_list], y_train)</span></span>
<span id="cb1-485"><a href="#cb1-485" aria-hidden="true" tabindex="-1"></a><span class="in">    </span></span>
<span id="cb1-486"><a href="#cb1-486" aria-hidden="true" tabindex="-1"></a><span class="in">    return model, selected_features_list</span></span>
<span id="cb1-487"><a href="#cb1-487" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-488"><a href="#cb1-488" aria-hidden="true" tabindex="-1"></a><span class="in"># Run backward selection</span></span>
<span id="cb1-489"><a href="#cb1-489" aria-hidden="true" tabindex="-1"></a><span class="in">model, selected_features_list = backward_selection(X_train, y_train)</span></span>
<span id="cb1-490"><a href="#cb1-490" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-491"><a href="#cb1-491" aria-hidden="true" tabindex="-1"></a><span class="in"># Get the names of the selected features</span></span>
<span id="cb1-492"><a href="#cb1-492" aria-hidden="true" tabindex="-1"></a><span class="in">selected_feature_names = selected_features_list</span></span>
<span id="cb1-493"><a href="#cb1-493" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-494"><a href="#cb1-494" aria-hidden="true" tabindex="-1"></a><span class="in"># Get the coefficients of the selected features</span></span>
<span id="cb1-495"><a href="#cb1-495" aria-hidden="true" tabindex="-1"></a><span class="in">selected_feature_coefficients = model.coef_</span></span>
<span id="cb1-496"><a href="#cb1-496" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-497"><a href="#cb1-497" aria-hidden="true" tabindex="-1"></a><span class="in"># Print the summary of the selected features and their coefficients</span></span>
<span id="cb1-498"><a href="#cb1-498" aria-hidden="true" tabindex="-1"></a><span class="in">for feature_name, coefficient in zip(selected_feature_names, selected_feature_coefficients):</span></span>
<span id="cb1-499"><a href="#cb1-499" aria-hidden="true" tabindex="-1"></a><span class="in">    print("Feature:", feature_name, "| Coefficient:", coefficient)</span></span>
<span id="cb1-500"><a href="#cb1-500" aria-hidden="true" tabindex="-1"></a><span class="in">      &lt;/pre&gt;</span></span>
<span id="cb1-501"><a href="#cb1-501" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb1-502"><a href="#cb1-502" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/li&gt;</span></span>
<span id="cb1-503"><a href="#cb1-503" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-504"><a href="#cb1-504" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/ul&gt;</span></span>
<span id="cb1-505"><a href="#cb1-505" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-506"><a href="#cb1-506" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/details&gt;</span></span>
<span id="cb1-507"><a href="#cb1-507" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-508"><a href="#cb1-508" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;details&gt;</span></span>
<span id="cb1-509"><a href="#cb1-509" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-510"><a href="#cb1-510" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;summary&gt;</span>STATA Code Example:<span class="kw">&lt;/summary&gt;</span></span>
<span id="cb1-511"><a href="#cb1-511" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-512"><a href="#cb1-512" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;ul&gt;</span></span>
<span id="cb1-513"><a href="#cb1-513" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-514"><a href="#cb1-514" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;li&gt;</span></span>
<span id="cb1-515"><a href="#cb1-515" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-516"><a href="#cb1-516" aria-hidden="true" tabindex="-1"></a><span class="in">```{=html}</span></span>
<span id="cb1-517"><a href="#cb1-517" aria-hidden="true" tabindex="-1"></a><span class="in">&lt;pre&gt;</span></span>
<span id="cb1-518"><a href="#cb1-518" aria-hidden="true" tabindex="-1"></a><span class="in">        // Backward Selection in STATA</span></span>
<span id="cb1-519"><a href="#cb1-519" aria-hidden="true" tabindex="-1"></a><span class="in">        stepwise, pr(0.05) backward: regress recovery_time age severity treatment gender comorbidities</span></span>
<span id="cb1-520"><a href="#cb1-520" aria-hidden="true" tabindex="-1"></a><span class="in">      &lt;/pre&gt;</span></span>
<span id="cb1-521"><a href="#cb1-521" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb1-522"><a href="#cb1-522" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/li&gt;</span></span>
<span id="cb1-523"><a href="#cb1-523" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-524"><a href="#cb1-524" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/ul&gt;</span></span>
<span id="cb1-525"><a href="#cb1-525" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-526"><a href="#cb1-526" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/details&gt;</span></span>
<span id="cb1-527"><a href="#cb1-527" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-528"><a href="#cb1-528" aria-hidden="true" tabindex="-1"></a><span class="fu">### Stepwise Selection</span></span>
<span id="cb1-529"><a href="#cb1-529" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-530"><a href="#cb1-530" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;details&gt;</span></span>
<span id="cb1-531"><a href="#cb1-531" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-532"><a href="#cb1-532" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;summary&gt;</span>JMP Instructions:<span class="kw">&lt;/summary&gt;</span></span>
<span id="cb1-533"><a href="#cb1-533" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-534"><a href="#cb1-534" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;ul&gt;</span></span>
<span id="cb1-535"><a href="#cb1-535" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-536"><a href="#cb1-536" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;li&gt;</span>Go to <span class="kw">&lt;code&gt;</span>Analyze<span class="kw">&lt;/code&gt;</span> <span class="sc">\&gt;</span> <span class="kw">&lt;code&gt;</span>Fit Model<span class="kw">&lt;/code&gt;</span>.<span class="kw">&lt;/li&gt;</span></span>
<span id="cb1-537"><a href="#cb1-537" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-538"><a href="#cb1-538" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;li&gt;</span>Select your dependent variable and move it to the <span class="kw">&lt;code&gt;</span>Y<span class="kw">&lt;/code&gt;</span> box.<span class="kw">&lt;/li&gt;</span></span>
<span id="cb1-539"><a href="#cb1-539" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-540"><a href="#cb1-540" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;li&gt;</span>Select your independent variables and move them to the <span class="kw">&lt;code&gt;</span>Construct Model Effects<span class="kw">&lt;/code&gt;</span> box.<span class="kw">&lt;/li&gt;</span></span>
<span id="cb1-541"><a href="#cb1-541" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-542"><a href="#cb1-542" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;li&gt;</span>Click on the <span class="kw">&lt;code&gt;</span>Stepwise<span class="kw">&lt;/code&gt;</span> button.<span class="kw">&lt;/li&gt;</span></span>
<span id="cb1-543"><a href="#cb1-543" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-544"><a href="#cb1-544" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;li&gt;</span>In the Stepwise Options dialog, set the <span class="kw">&lt;code&gt;</span>Direction<span class="kw">&lt;/code&gt;</span> to <span class="kw">&lt;code&gt;</span>Mixed<span class="kw">&lt;/code&gt;</span> (for both forward and backward steps).<span class="kw">&lt;/li&gt;</span></span>
<span id="cb1-545"><a href="#cb1-545" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-546"><a href="#cb1-546" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;li&gt;</span>Specify the stopping criterion (e.g., p-value threshold) and click <span class="kw">&lt;code&gt;</span>OK<span class="kw">&lt;/code&gt;</span>.<span class="kw">&lt;/li&gt;</span></span>
<span id="cb1-547"><a href="#cb1-547" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-548"><a href="#cb1-548" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;li&gt;</span>Click <span class="kw">&lt;code&gt;</span>Run<span class="kw">&lt;/code&gt;</span> to perform the stepwise selection.<span class="kw">&lt;/li&gt;</span></span>
<span id="cb1-549"><a href="#cb1-549" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-550"><a href="#cb1-550" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/ul&gt;</span></span>
<span id="cb1-551"><a href="#cb1-551" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-552"><a href="#cb1-552" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/details&gt;</span></span>
<span id="cb1-553"><a href="#cb1-553" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-554"><a href="#cb1-554" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;details&gt;</span></span>
<span id="cb1-555"><a href="#cb1-555" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-556"><a href="#cb1-556" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;summary&gt;</span>R Code Example:<span class="kw">&lt;/summary&gt;</span></span>
<span id="cb1-557"><a href="#cb1-557" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-558"><a href="#cb1-558" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;ul&gt;</span></span>
<span id="cb1-559"><a href="#cb1-559" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-560"><a href="#cb1-560" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;li&gt;</span></span>
<span id="cb1-561"><a href="#cb1-561" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-562"><a href="#cb1-562" aria-hidden="true" tabindex="-1"></a><span class="in">```{=html}</span></span>
<span id="cb1-563"><a href="#cb1-563" aria-hidden="true" tabindex="-1"></a><span class="in">&lt;pre&gt;</span></span>
<span id="cb1-564"><a href="#cb1-564" aria-hidden="true" tabindex="-1"></a><span class="in">        # Stepwise Selection in R</span></span>
<span id="cb1-565"><a href="#cb1-565" aria-hidden="true" tabindex="-1"></a><span class="in">        library(MASS)</span></span>
<span id="cb1-566"><a href="#cb1-566" aria-hidden="true" tabindex="-1"></a><span class="in">        </span></span>
<span id="cb1-567"><a href="#cb1-567" aria-hidden="true" tabindex="-1"></a><span class="in">        # Full model</span></span>
<span id="cb1-568"><a href="#cb1-568" aria-hidden="true" tabindex="-1"></a><span class="in">        full_model &lt;- lm(`Minimum Price ($1000)` ~ `Maximum Horsepower` + `Fuel Tank Capacity`+ `Passenger Capacity`, data = cars1993)</span></span>
<span id="cb1-569"><a href="#cb1-569" aria-hidden="true" tabindex="-1"></a><span class="in">        </span></span>
<span id="cb1-570"><a href="#cb1-570" aria-hidden="true" tabindex="-1"></a><span class="in">        # Stepwise selection</span></span>
<span id="cb1-571"><a href="#cb1-571" aria-hidden="true" tabindex="-1"></a><span class="in">        step_model &lt;- stepAIC(full_model, direction = "both")</span></span>
<span id="cb1-572"><a href="#cb1-572" aria-hidden="true" tabindex="-1"></a><span class="in">        </span></span>
<span id="cb1-573"><a href="#cb1-573" aria-hidden="true" tabindex="-1"></a><span class="in">        summary(step_model)</span></span>
<span id="cb1-574"><a href="#cb1-574" aria-hidden="true" tabindex="-1"></a><span class="in">      &lt;/pre&gt;</span></span>
<span id="cb1-575"><a href="#cb1-575" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb1-576"><a href="#cb1-576" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/li&gt;</span></span>
<span id="cb1-577"><a href="#cb1-577" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-578"><a href="#cb1-578" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/ul&gt;</span></span>
<span id="cb1-579"><a href="#cb1-579" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-580"><a href="#cb1-580" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/details&gt;</span></span>
<span id="cb1-581"><a href="#cb1-581" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-582"><a href="#cb1-582" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;details&gt;</span></span>
<span id="cb1-583"><a href="#cb1-583" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-584"><a href="#cb1-584" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;summary&gt;</span>Python Code Example:<span class="kw">&lt;/summary&gt;</span></span>
<span id="cb1-585"><a href="#cb1-585" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-586"><a href="#cb1-586" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;ul&gt;</span></span>
<span id="cb1-587"><a href="#cb1-587" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-588"><a href="#cb1-588" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;li&gt;</span></span>
<span id="cb1-589"><a href="#cb1-589" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-590"><a href="#cb1-590" aria-hidden="true" tabindex="-1"></a><span class="in">```{=html}</span></span>
<span id="cb1-591"><a href="#cb1-591" aria-hidden="true" tabindex="-1"></a><span class="in">&lt;pre&gt;</span></span>
<span id="cb1-592"><a href="#cb1-592" aria-hidden="true" tabindex="-1"></a><span class="in">      </span></span>
<span id="cb1-593"><a href="#cb1-593" aria-hidden="true" tabindex="-1"></a><span class="in"> # Stepwise Selection in Python</span></span>
<span id="cb1-594"><a href="#cb1-594" aria-hidden="true" tabindex="-1"></a><span class="in">import pandas as pd</span></span>
<span id="cb1-595"><a href="#cb1-595" aria-hidden="true" tabindex="-1"></a><span class="in">import statsmodels.api as sm</span></span>
<span id="cb1-596"><a href="#cb1-596" aria-hidden="true" tabindex="-1"></a><span class="in">from sklearn.datasets import load_iris</span></span>
<span id="cb1-597"><a href="#cb1-597" aria-hidden="true" tabindex="-1"></a><span class="in">from sklearn.model_selection import train_test_split</span></span>
<span id="cb1-598"><a href="#cb1-598" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-599"><a href="#cb1-599" aria-hidden="true" tabindex="-1"></a><span class="in"># Load Iris data</span></span>
<span id="cb1-600"><a href="#cb1-600" aria-hidden="true" tabindex="-1"></a><span class="in">iris = load_iris()</span></span>
<span id="cb1-601"><a href="#cb1-601" aria-hidden="true" tabindex="-1"></a><span class="in">X = pd.DataFrame(iris.data, columns=iris.feature_names)</span></span>
<span id="cb1-602"><a href="#cb1-602" aria-hidden="true" tabindex="-1"></a><span class="in">y = iris.target</span></span>
<span id="cb1-603"><a href="#cb1-603" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-604"><a href="#cb1-604" aria-hidden="true" tabindex="-1"></a><span class="in"># Split the data into training and testing sets</span></span>
<span id="cb1-605"><a href="#cb1-605" aria-hidden="true" tabindex="-1"></a><span class="in">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)</span></span>
<span id="cb1-606"><a href="#cb1-606" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-607"><a href="#cb1-607" aria-hidden="true" tabindex="-1"></a><span class="in"># Add the target variable to the training data</span></span>
<span id="cb1-608"><a href="#cb1-608" aria-hidden="true" tabindex="-1"></a><span class="in">train_data = X_train.copy()</span></span>
<span id="cb1-609"><a href="#cb1-609" aria-hidden="true" tabindex="-1"></a><span class="in">train_data['target'] = y_train</span></span>
<span id="cb1-610"><a href="#cb1-610" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-611"><a href="#cb1-611" aria-hidden="true" tabindex="-1"></a><span class="in"># Stepwise selection</span></span>
<span id="cb1-612"><a href="#cb1-612" aria-hidden="true" tabindex="-1"></a><span class="in">def stepwise_selected(data, response):</span></span>
<span id="cb1-613"><a href="#cb1-613" aria-hidden="true" tabindex="-1"></a><span class="in">    def calculate_aic(model):</span></span>
<span id="cb1-614"><a href="#cb1-614" aria-hidden="true" tabindex="-1"></a><span class="in">        return sm.OLS(data[response], model).fit().aic</span></span>
<span id="cb1-615"><a href="#cb1-615" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-616"><a href="#cb1-616" aria-hidden="true" tabindex="-1"></a><span class="in">    predictors = list(data.columns)</span></span>
<span id="cb1-617"><a href="#cb1-617" aria-hidden="true" tabindex="-1"></a><span class="in">    predictors.remove(response)</span></span>
<span id="cb1-618"><a href="#cb1-618" aria-hidden="true" tabindex="-1"></a><span class="in">    selected = []</span></span>
<span id="cb1-619"><a href="#cb1-619" aria-hidden="true" tabindex="-1"></a><span class="in">    aic_current = float('inf')</span></span>
<span id="cb1-620"><a href="#cb1-620" aria-hidden="true" tabindex="-1"></a><span class="in">    while predictors:</span></span>
<span id="cb1-621"><a href="#cb1-621" aria-hidden="true" tabindex="-1"></a><span class="in">        aic_with_candidates = []</span></span>
<span id="cb1-622"><a href="#cb1-622" aria-hidden="true" tabindex="-1"></a><span class="in">        for candidate in predictors:</span></span>
<span id="cb1-623"><a href="#cb1-623" aria-hidden="true" tabindex="-1"></a><span class="in">            model = sm.add_constant(data[selected + [candidate]])</span></span>
<span id="cb1-624"><a href="#cb1-624" aria-hidden="true" tabindex="-1"></a><span class="in">            aic = calculate_aic(model)</span></span>
<span id="cb1-625"><a href="#cb1-625" aria-hidden="true" tabindex="-1"></a><span class="in">            aic_with_candidates.append((aic, candidate))</span></span>
<span id="cb1-626"><a href="#cb1-626" aria-hidden="true" tabindex="-1"></a><span class="in">        aic_with_candidates.sort()</span></span>
<span id="cb1-627"><a href="#cb1-627" aria-hidden="true" tabindex="-1"></a><span class="in">        best_aic, best_candidate = aic_with_candidates[0]</span></span>
<span id="cb1-628"><a href="#cb1-628" aria-hidden="true" tabindex="-1"></a><span class="in">        if aic_current &gt; best_aic:</span></span>
<span id="cb1-629"><a href="#cb1-629" aria-hidden="true" tabindex="-1"></a><span class="in">            predictors.remove(best_candidate)</span></span>
<span id="cb1-630"><a href="#cb1-630" aria-hidden="true" tabindex="-1"></a><span class="in">            selected.append(best_candidate)</span></span>
<span id="cb1-631"><a href="#cb1-631" aria-hidden="true" tabindex="-1"></a><span class="in">            aic_current = best_aic</span></span>
<span id="cb1-632"><a href="#cb1-632" aria-hidden="true" tabindex="-1"></a><span class="in">        else:</span></span>
<span id="cb1-633"><a href="#cb1-633" aria-hidden="true" tabindex="-1"></a><span class="in">            break</span></span>
<span id="cb1-634"><a href="#cb1-634" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-635"><a href="#cb1-635" aria-hidden="true" tabindex="-1"></a><span class="in">        # Check if there are selected features before attempting to remove any</span></span>
<span id="cb1-636"><a href="#cb1-636" aria-hidden="true" tabindex="-1"></a><span class="in">        if selected:</span></span>
<span id="cb1-637"><a href="#cb1-637" aria-hidden="true" tabindex="-1"></a><span class="in">            remaining = list(set(data.columns) - set(selected) - {response})</span></span>
<span id="cb1-638"><a href="#cb1-638" aria-hidden="true" tabindex="-1"></a><span class="in">            for candidate in remaining:</span></span>
<span id="cb1-639"><a href="#cb1-639" aria-hidden="true" tabindex="-1"></a><span class="in">                # Check if the candidate is still in the selected list</span></span>
<span id="cb1-640"><a href="#cb1-640" aria-hidden="true" tabindex="-1"></a><span class="in">                if candidate in selected: </span></span>
<span id="cb1-641"><a href="#cb1-641" aria-hidden="true" tabindex="-1"></a><span class="in">                    model = sm.add_constant(data[selected].drop([candidate], axis=1))</span></span>
<span id="cb1-642"><a href="#cb1-642" aria-hidden="true" tabindex="-1"></a><span class="in">                    aic = calculate_aic(model)</span></span>
<span id="cb1-643"><a href="#cb1-643" aria-hidden="true" tabindex="-1"></a><span class="in">                    if aic &lt; aic_current:</span></span>
<span id="cb1-644"><a href="#cb1-644" aria-hidden="true" tabindex="-1"></a><span class="in">                        selected.remove(candidate)</span></span>
<span id="cb1-645"><a href="#cb1-645" aria-hidden="true" tabindex="-1"></a><span class="in">                        aic_current = aic</span></span>
<span id="cb1-646"><a href="#cb1-646" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-647"><a href="#cb1-647" aria-hidden="true" tabindex="-1"></a><span class="in">    final_model = sm.OLS(data[response], sm.add_constant(data[selected])).fit()</span></span>
<span id="cb1-648"><a href="#cb1-648" aria-hidden="true" tabindex="-1"></a><span class="in">    return final_model</span></span>
<span id="cb1-649"><a href="#cb1-649" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-650"><a href="#cb1-650" aria-hidden="true" tabindex="-1"></a><span class="in"># Apply stepwise selection to Iris dataset</span></span>
<span id="cb1-651"><a href="#cb1-651" aria-hidden="true" tabindex="-1"></a><span class="in">selected_model = stepwise_selected(train_data, 'target')</span></span>
<span id="cb1-652"><a href="#cb1-652" aria-hidden="true" tabindex="-1"></a><span class="in">print(selected_model.summary())</span></span>
<span id="cb1-653"><a href="#cb1-653" aria-hidden="true" tabindex="-1"></a><span class="in">      &lt;/pre&gt;</span></span>
<span id="cb1-654"><a href="#cb1-654" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb1-655"><a href="#cb1-655" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/li&gt;</span></span>
<span id="cb1-656"><a href="#cb1-656" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-657"><a href="#cb1-657" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/ul&gt;</span></span>
<span id="cb1-658"><a href="#cb1-658" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-659"><a href="#cb1-659" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/details&gt;</span></span>
<span id="cb1-660"><a href="#cb1-660" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-661"><a href="#cb1-661" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;details&gt;</span></span>
<span id="cb1-662"><a href="#cb1-662" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-663"><a href="#cb1-663" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;summary&gt;</span>STATA Code Example:<span class="kw">&lt;/summary&gt;</span></span>
<span id="cb1-664"><a href="#cb1-664" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-665"><a href="#cb1-665" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;ul&gt;</span></span>
<span id="cb1-666"><a href="#cb1-666" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-667"><a href="#cb1-667" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;li&gt;</span></span>
<span id="cb1-668"><a href="#cb1-668" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-669"><a href="#cb1-669" aria-hidden="true" tabindex="-1"></a><span class="in">```{=html}</span></span>
<span id="cb1-670"><a href="#cb1-670" aria-hidden="true" tabindex="-1"></a><span class="in">&lt;pre&gt;</span></span>
<span id="cb1-671"><a href="#cb1-671" aria-hidden="true" tabindex="-1"></a><span class="in">        // Stepwise Selection in STATA</span></span>
<span id="cb1-672"><a href="#cb1-672" aria-hidden="true" tabindex="-1"></a><span class="in">        stepwise, pr(0.05): regress recovery_time age severity treatment gender comorbidities</span></span>
<span id="cb1-673"><a href="#cb1-673" aria-hidden="true" tabindex="-1"></a><span class="in">      &lt;/pre&gt;</span></span>
<span id="cb1-674"><a href="#cb1-674" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb1-675"><a href="#cb1-675" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/li&gt;</span></span>
<span id="cb1-676"><a href="#cb1-676" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-677"><a href="#cb1-677" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/ul&gt;</span></span>
<span id="cb1-678"><a href="#cb1-678" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-679"><a href="#cb1-679" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/details&gt;</span></span>
<span id="cb1-680"><a href="#cb1-680" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-681"><a href="#cb1-681" aria-hidden="true" tabindex="-1"></a><span class="fu">### Lasso</span></span>
<span id="cb1-682"><a href="#cb1-682" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-683"><a href="#cb1-683" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;details&gt;</span></span>
<span id="cb1-684"><a href="#cb1-684" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-685"><a href="#cb1-685" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;summary&gt;</span>JMP Instructions:<span class="kw">&lt;/summary&gt;</span></span>
<span id="cb1-686"><a href="#cb1-686" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-687"><a href="#cb1-687" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;ul&gt;</span></span>
<span id="cb1-688"><a href="#cb1-688" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-689"><a href="#cb1-689" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;li&gt;</span>Go to <span class="kw">&lt;code&gt;</span>Analyze<span class="kw">&lt;/code&gt;</span> <span class="sc">\&gt;</span> <span class="kw">&lt;code&gt;</span>Fit Model<span class="kw">&lt;/code&gt;</span>.<span class="kw">&lt;/li&gt;</span></span>
<span id="cb1-690"><a href="#cb1-690" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-691"><a href="#cb1-691" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;li&gt;</span>Select your dependent variable and move it to the <span class="kw">&lt;code&gt;</span>Y<span class="kw">&lt;/code&gt;</span> box.<span class="kw">&lt;/li&gt;</span></span>
<span id="cb1-692"><a href="#cb1-692" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-693"><a href="#cb1-693" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;li&gt;</span>Select your independent variables and move them to the <span class="kw">&lt;code&gt;</span>Construct Model Effects<span class="kw">&lt;/code&gt;</span> box.<span class="kw">&lt;/li&gt;</span></span>
<span id="cb1-694"><a href="#cb1-694" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-695"><a href="#cb1-695" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;li&gt;</span>Click on the <span class="kw">&lt;code&gt;</span>Personality<span class="kw">&lt;/code&gt;</span> dropdown and select <span class="kw">&lt;code&gt;</span>Lasso<span class="kw">&lt;/code&gt;</span>.<span class="kw">&lt;/li&gt;</span></span>
<span id="cb1-696"><a href="#cb1-696" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-697"><a href="#cb1-697" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;li&gt;</span>Specify the tuning parameter (lambda) or use cross-validation to select it.<span class="kw">&lt;/li&gt;</span></span>
<span id="cb1-698"><a href="#cb1-698" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-699"><a href="#cb1-699" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;li&gt;</span>Click <span class="kw">&lt;code&gt;</span>Run<span class="kw">&lt;/code&gt;</span> to fit the lasso model.<span class="kw">&lt;/li&gt;</span></span>
<span id="cb1-700"><a href="#cb1-700" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-701"><a href="#cb1-701" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/ul&gt;</span></span>
<span id="cb1-702"><a href="#cb1-702" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-703"><a href="#cb1-703" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/details&gt;</span></span>
<span id="cb1-704"><a href="#cb1-704" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-705"><a href="#cb1-705" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;details&gt;</span></span>
<span id="cb1-706"><a href="#cb1-706" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-707"><a href="#cb1-707" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;summary&gt;</span>R Code Example:<span class="kw">&lt;/summary&gt;</span></span>
<span id="cb1-708"><a href="#cb1-708" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-709"><a href="#cb1-709" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;ul&gt;</span></span>
<span id="cb1-710"><a href="#cb1-710" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-711"><a href="#cb1-711" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;li&gt;</span></span>
<span id="cb1-712"><a href="#cb1-712" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-713"><a href="#cb1-713" aria-hidden="true" tabindex="-1"></a><span class="in">```{=html}</span></span>
<span id="cb1-714"><a href="#cb1-714" aria-hidden="true" tabindex="-1"></a><span class="in">&lt;pre&gt;</span></span>
<span id="cb1-715"><a href="#cb1-715" aria-hidden="true" tabindex="-1"></a><span class="in">       # Install glmnet package if not already installed</span></span>
<span id="cb1-716"><a href="#cb1-716" aria-hidden="true" tabindex="-1"></a><span class="in">install.packages("glmnet")</span></span>
<span id="cb1-717"><a href="#cb1-717" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-718"><a href="#cb1-718" aria-hidden="true" tabindex="-1"></a><span class="in"># Lasso in R</span></span>
<span id="cb1-719"><a href="#cb1-719" aria-hidden="true" tabindex="-1"></a><span class="in">library(glmnet)</span></span>
<span id="cb1-720"><a href="#cb1-720" aria-hidden="true" tabindex="-1"></a><span class="in">        </span></span>
<span id="cb1-721"><a href="#cb1-721" aria-hidden="true" tabindex="-1"></a><span class="in"># Prepare data</span></span>
<span id="cb1-722"><a href="#cb1-722" aria-hidden="true" tabindex="-1"></a><span class="in">  data_2&lt;-read.csv("Cars 1993.csv")</span></span>
<span id="cb1-723"><a href="#cb1-723" aria-hidden="true" tabindex="-1"></a><span class="in">X &lt;- model.matrix(`Minimum.Price...1000.` ~ `Maximum.Horsepower` + `Fuel.Tank.Capacity` + `Passenger.Capacity`, data = data_2)[, -1]</span></span>
<span id="cb1-724"><a href="#cb1-724" aria-hidden="true" tabindex="-1"></a><span class="in">y &lt;- data_2$`Minimum.Price...1000.`</span></span>
<span id="cb1-725"><a href="#cb1-725" aria-hidden="true" tabindex="-1"></a><span class="in">        </span></span>
<span id="cb1-726"><a href="#cb1-726" aria-hidden="true" tabindex="-1"></a><span class="in">#Fit LASSO using cross-validation</span></span>
<span id="cb1-727"><a href="#cb1-727" aria-hidden="true" tabindex="-1"></a><span class="in">set.seed(123) #For reproducibility</span></span>
<span id="cb1-728"><a href="#cb1-728" aria-hidden="true" tabindex="-1"></a><span class="in">cv_fit &lt;- cv.glmnet(X, y, alpha = 1)</span></span>
<span id="cb1-729"><a href="#cb1-729" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-730"><a href="#cb1-730" aria-hidden="true" tabindex="-1"></a><span class="in">#Plot the cross-validation</span></span>
<span id="cb1-731"><a href="#cb1-731" aria-hidden="true" tabindex="-1"></a><span class="in">plot(cv_fit)</span></span>
<span id="cb1-732"><a href="#cb1-732" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-733"><a href="#cb1-733" aria-hidden="true" tabindex="-1"></a><span class="in">#Extract the coefficients of the best model</span></span>
<span id="cb1-734"><a href="#cb1-734" aria-hidden="true" tabindex="-1"></a><span class="in">best_lambda &lt;- cv_fit$lambda.min</span></span>
<span id="cb1-735"><a href="#cb1-735" aria-hidden="true" tabindex="-1"></a><span class="in">lasso_coefficients &lt;- coef(cv_fit, s = "lambda.min")</span></span>
<span id="cb1-736"><a href="#cb1-736" aria-hidden="true" tabindex="-1"></a><span class="in">print(lasso_coefficients)</span></span>
<span id="cb1-737"><a href="#cb1-737" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-738"><a href="#cb1-738" aria-hidden="true" tabindex="-1"></a><span class="in">      &lt;/pre&gt;</span></span>
<span id="cb1-739"><a href="#cb1-739" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb1-740"><a href="#cb1-740" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/li&gt;</span></span>
<span id="cb1-741"><a href="#cb1-741" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-742"><a href="#cb1-742" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/ul&gt;</span></span>
<span id="cb1-743"><a href="#cb1-743" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-744"><a href="#cb1-744" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/details&gt;</span></span>
<span id="cb1-745"><a href="#cb1-745" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-746"><a href="#cb1-746" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;details&gt;</span></span>
<span id="cb1-747"><a href="#cb1-747" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-748"><a href="#cb1-748" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;summary&gt;</span>Python Code Example:<span class="kw">&lt;/summary&gt;</span></span>
<span id="cb1-749"><a href="#cb1-749" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-750"><a href="#cb1-750" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;ul&gt;</span></span>
<span id="cb1-751"><a href="#cb1-751" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-752"><a href="#cb1-752" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;li&gt;</span></span>
<span id="cb1-753"><a href="#cb1-753" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-754"><a href="#cb1-754" aria-hidden="true" tabindex="-1"></a><span class="in">```{=html}</span></span>
<span id="cb1-755"><a href="#cb1-755" aria-hidden="true" tabindex="-1"></a><span class="in">&lt;pre&gt;</span></span>
<span id="cb1-756"><a href="#cb1-756" aria-hidden="true" tabindex="-1"></a><span class="in">        </span></span>
<span id="cb1-757"><a href="#cb1-757" aria-hidden="true" tabindex="-1"></a><span class="in">        </span></span>
<span id="cb1-758"><a href="#cb1-758" aria-hidden="true" tabindex="-1"></a><span class="in">        # Lasso in Python</span></span>
<span id="cb1-759"><a href="#cb1-759" aria-hidden="true" tabindex="-1"></a><span class="in">       import pandas as pd</span></span>
<span id="cb1-760"><a href="#cb1-760" aria-hidden="true" tabindex="-1"></a><span class="in">import numpy as np</span></span>
<span id="cb1-761"><a href="#cb1-761" aria-hidden="true" tabindex="-1"></a><span class="in">from sklearn.datasets import load_iris</span></span>
<span id="cb1-762"><a href="#cb1-762" aria-hidden="true" tabindex="-1"></a><span class="in">from sklearn.model_selection import train_test_split, GridSearchCV</span></span>
<span id="cb1-763"><a href="#cb1-763" aria-hidden="true" tabindex="-1"></a><span class="in">from sklearn.linear_model import Lasso</span></span>
<span id="cb1-764"><a href="#cb1-764" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-765"><a href="#cb1-765" aria-hidden="true" tabindex="-1"></a><span class="in"># Load Iris data</span></span>
<span id="cb1-766"><a href="#cb1-766" aria-hidden="true" tabindex="-1"></a><span class="in">iris = load_iris()</span></span>
<span id="cb1-767"><a href="#cb1-767" aria-hidden="true" tabindex="-1"></a><span class="in">X = pd.DataFrame(iris.data, columns=iris.feature_names)</span></span>
<span id="cb1-768"><a href="#cb1-768" aria-hidden="true" tabindex="-1"></a><span class="in">y = iris.target</span></span>
<span id="cb1-769"><a href="#cb1-769" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-770"><a href="#cb1-770" aria-hidden="true" tabindex="-1"></a><span class="in"># Split the data into training and testing sets</span></span>
<span id="cb1-771"><a href="#cb1-771" aria-hidden="true" tabindex="-1"></a><span class="in">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)</span></span>
<span id="cb1-772"><a href="#cb1-772" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-773"><a href="#cb1-773" aria-hidden="true" tabindex="-1"></a><span class="in"># Perform LASSO with cross-validation to find the best alpha</span></span>
<span id="cb1-774"><a href="#cb1-774" aria-hidden="true" tabindex="-1"></a><span class="in">lasso = Lasso(max_iter=10000)</span></span>
<span id="cb1-775"><a href="#cb1-775" aria-hidden="true" tabindex="-1"></a><span class="in">param_grid = {'alpha': np.logspace(-4, 0, 100)}  # Test alpha values from 0.0001 to 1</span></span>
<span id="cb1-776"><a href="#cb1-776" aria-hidden="true" tabindex="-1"></a><span class="in">lasso_cv = GridSearchCV(lasso, param_grid, cv=5)</span></span>
<span id="cb1-777"><a href="#cb1-777" aria-hidden="true" tabindex="-1"></a><span class="in">lasso_cv.fit(X_train, y_train)</span></span>
<span id="cb1-778"><a href="#cb1-778" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-779"><a href="#cb1-779" aria-hidden="true" tabindex="-1"></a><span class="in"># Get the best alpha value and the corresponding model</span></span>
<span id="cb1-780"><a href="#cb1-780" aria-hidden="true" tabindex="-1"></a><span class="in">best_alpha = lasso_cv.best_params_['alpha']</span></span>
<span id="cb1-781"><a href="#cb1-781" aria-hidden="true" tabindex="-1"></a><span class="in">best_model = lasso_cv.best_estimator_</span></span>
<span id="cb1-782"><a href="#cb1-782" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-783"><a href="#cb1-783" aria-hidden="true" tabindex="-1"></a><span class="in"># Get the selected features based on the best model</span></span>
<span id="cb1-784"><a href="#cb1-784" aria-hidden="true" tabindex="-1"></a><span class="in">selected_features = X_train.columns[best_model.coef_ != 0]</span></span>
<span id="cb1-785"><a href="#cb1-785" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-786"><a href="#cb1-786" aria-hidden="true" tabindex="-1"></a><span class="in"># Print the best alpha value and selected features</span></span>
<span id="cb1-787"><a href="#cb1-787" aria-hidden="true" tabindex="-1"></a><span class="in">print("Best alpha:", best_alpha)</span></span>
<span id="cb1-788"><a href="#cb1-788" aria-hidden="true" tabindex="-1"></a><span class="in">print("Selected features:", selected_features)</span></span>
<span id="cb1-789"><a href="#cb1-789" aria-hidden="true" tabindex="-1"></a><span class="in">      &lt;/pre&gt;</span></span>
<span id="cb1-790"><a href="#cb1-790" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb1-791"><a href="#cb1-791" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/li&gt;</span></span>
<span id="cb1-792"><a href="#cb1-792" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-793"><a href="#cb1-793" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/ul&gt;</span></span>
<span id="cb1-794"><a href="#cb1-794" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-795"><a href="#cb1-795" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/details&gt;</span></span>
<span id="cb1-796"><a href="#cb1-796" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-797"><a href="#cb1-797" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;details&gt;</span></span>
<span id="cb1-798"><a href="#cb1-798" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-799"><a href="#cb1-799" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;summary&gt;</span>STATA Code Example:<span class="kw">&lt;/summary&gt;</span></span>
<span id="cb1-800"><a href="#cb1-800" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-801"><a href="#cb1-801" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;ul&gt;</span></span>
<span id="cb1-802"><a href="#cb1-802" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-803"><a href="#cb1-803" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;li&gt;</span></span>
<span id="cb1-804"><a href="#cb1-804" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-805"><a href="#cb1-805" aria-hidden="true" tabindex="-1"></a><span class="in">```{=html}</span></span>
<span id="cb1-806"><a href="#cb1-806" aria-hidden="true" tabindex="-1"></a><span class="in">&lt;pre&gt;</span></span>
<span id="cb1-807"><a href="#cb1-807" aria-hidden="true" tabindex="-1"></a><span class="in">        // Lasso in STATA</span></span>
<span id="cb1-808"><a href="#cb1-808" aria-hidden="true" tabindex="-1"></a><span class="in">        lassoreg recovery_time age severity treatment gender comorbidities</span></span>
<span id="cb1-809"><a href="#cb1-809" aria-hidden="true" tabindex="-1"></a><span class="in">      &lt;/pre&gt;</span></span>
<span id="cb1-810"><a href="#cb1-810" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb1-811"><a href="#cb1-811" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/li&gt;</span></span>
<span id="cb1-812"><a href="#cb1-812" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-813"><a href="#cb1-813" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/ul&gt;</span></span>
<span id="cb1-814"><a href="#cb1-814" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-815"><a href="#cb1-815" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/details&gt;</span></span>
<span id="cb1-816"><a href="#cb1-816" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-817"><a href="#cb1-817" aria-hidden="true" tabindex="-1"></a><span class="fu">### Multi-Step (Hierarchical Regression)</span></span>
<span id="cb1-818"><a href="#cb1-818" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-819"><a href="#cb1-819" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;details&gt;</span></span>
<span id="cb1-820"><a href="#cb1-820" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-821"><a href="#cb1-821" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;summary&gt;</span>JMP Instructions:<span class="kw">&lt;/summary&gt;</span></span>
<span id="cb1-822"><a href="#cb1-822" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-823"><a href="#cb1-823" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;ul&gt;</span></span>
<span id="cb1-824"><a href="#cb1-824" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-825"><a href="#cb1-825" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;li&gt;</span>Go to <span class="kw">&lt;code&gt;</span>Analyze<span class="kw">&lt;/code&gt;</span> <span class="sc">\&gt;</span> <span class="kw">&lt;code&gt;</span>Fit Model<span class="kw">&lt;/code&gt;</span>.<span class="kw">&lt;/li&gt;</span></span>
<span id="cb1-826"><a href="#cb1-826" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-827"><a href="#cb1-827" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;li&gt;</span>Select your dependent variable and move it to the <span class="kw">&lt;code&gt;</span>Y<span class="kw">&lt;/code&gt;</span> box.<span class="kw">&lt;/li&gt;</span></span>
<span id="cb1-828"><a href="#cb1-828" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-829"><a href="#cb1-829" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;li&gt;</span>Select the first set of independent variables and move them to the <span class="kw">&lt;code&gt;</span>Construct Model Effects<span class="kw">&lt;/code&gt;</span> box.<span class="kw">&lt;/li&gt;</span></span>
<span id="cb1-830"><a href="#cb1-830" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-831"><a href="#cb1-831" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;li&gt;</span>Click <span class="kw">&lt;code&gt;</span>Run<span class="kw">&lt;/code&gt;</span> to fit the first model.<span class="kw">&lt;/li&gt;</span></span>
<span id="cb1-832"><a href="#cb1-832" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-833"><a href="#cb1-833" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;li&gt;</span>To add more variables, go to <span class="kw">&lt;code&gt;</span>Redo<span class="kw">&lt;/code&gt;</span> <span class="sc">\&gt;</span> <span class="kw">&lt;code&gt;</span>Modeling<span class="kw">&lt;/code&gt;</span> <span class="sc">\&gt;</span> <span class="kw">&lt;code&gt;</span>Add Predictors<span class="kw">&lt;/code&gt;</span>.<span class="kw">&lt;/li&gt;</span></span>
<span id="cb1-834"><a href="#cb1-834" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-835"><a href="#cb1-835" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;li&gt;</span>Add the next set of variables and click <span class="kw">&lt;code&gt;</span>Run<span class="kw">&lt;/code&gt;</span> again.<span class="kw">&lt;/li&gt;</span></span>
<span id="cb1-836"><a href="#cb1-836" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-837"><a href="#cb1-837" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;li&gt;</span>Repeat the process until all variables are included, fitting the model in steps.<span class="kw">&lt;/li&gt;</span></span>
<span id="cb1-838"><a href="#cb1-838" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-839"><a href="#cb1-839" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/ul&gt;</span></span>
<span id="cb1-840"><a href="#cb1-840" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-841"><a href="#cb1-841" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/details&gt;</span></span>
<span id="cb1-842"><a href="#cb1-842" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-843"><a href="#cb1-843" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;details&gt;</span></span>
<span id="cb1-844"><a href="#cb1-844" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-845"><a href="#cb1-845" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;summary&gt;</span>R Code Example:<span class="kw">&lt;/summary&gt;</span></span>
<span id="cb1-846"><a href="#cb1-846" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-847"><a href="#cb1-847" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;ul&gt;</span></span>
<span id="cb1-848"><a href="#cb1-848" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-849"><a href="#cb1-849" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;li&gt;</span></span>
<span id="cb1-850"><a href="#cb1-850" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-851"><a href="#cb1-851" aria-hidden="true" tabindex="-1"></a><span class="in">```{=html}</span></span>
<span id="cb1-852"><a href="#cb1-852" aria-hidden="true" tabindex="-1"></a><span class="in">&lt;pre&gt;</span></span>
<span id="cb1-853"><a href="#cb1-853" aria-hidden="true" tabindex="-1"></a><span class="in">        # Multi-Step (Hierarchical Regression) in R</span></span>
<span id="cb1-854"><a href="#cb1-854" aria-hidden="true" tabindex="-1"></a><span class="in">        # Step 1</span></span>
<span id="cb1-855"><a href="#cb1-855" aria-hidden="true" tabindex="-1"></a><span class="in">        model1&lt;- lm(`Minimum Price ($1000)` ~ `Maximum Horsepower`, data = cars1993)</span></span>
<span id="cb1-856"><a href="#cb1-856" aria-hidden="true" tabindex="-1"></a><span class="in">        </span></span>
<span id="cb1-857"><a href="#cb1-857" aria-hidden="true" tabindex="-1"></a><span class="in">        # Step 2</span></span>
<span id="cb1-858"><a href="#cb1-858" aria-hidden="true" tabindex="-1"></a><span class="in">        model2 &lt;- lm(`Minimum Price ($1000)` ~ `Maximum Horsepower` + `Fuel Tank Capacity`, data = cars1993)</span></span>
<span id="cb1-859"><a href="#cb1-859" aria-hidden="true" tabindex="-1"></a><span class="in">        </span></span>
<span id="cb1-860"><a href="#cb1-860" aria-hidden="true" tabindex="-1"></a><span class="in">        # Step 3</span></span>
<span id="cb1-861"><a href="#cb1-861" aria-hidden="true" tabindex="-1"></a><span class="in">        model3 &lt;- lm(`Minimum Price ($1000)` ~ `Maximum Horsepower` + `Fuel Tank Capacity`+ `Passenger Capacity`, data = cars1993)</span></span>
<span id="cb1-862"><a href="#cb1-862" aria-hidden="true" tabindex="-1"></a><span class="in">        </span></span>
<span id="cb1-863"><a href="#cb1-863" aria-hidden="true" tabindex="-1"></a><span class="in">        # Compare models</span></span>
<span id="cb1-864"><a href="#cb1-864" aria-hidden="true" tabindex="-1"></a><span class="in">        summary(model1)</span></span>
<span id="cb1-865"><a href="#cb1-865" aria-hidden="true" tabindex="-1"></a><span class="in">        summary(model2)</span></span>
<span id="cb1-866"><a href="#cb1-866" aria-hidden="true" tabindex="-1"></a><span class="in">        summary(model3)</span></span>
<span id="cb1-867"><a href="#cb1-867" aria-hidden="true" tabindex="-1"></a><span class="in">        </span></span>
<span id="cb1-868"><a href="#cb1-868" aria-hidden="true" tabindex="-1"></a><span class="in">        #ANOVA of models</span></span>
<span id="cb1-869"><a href="#cb1-869" aria-hidden="true" tabindex="-1"></a><span class="in">        anova(model1, model2, model3)</span></span>
<span id="cb1-870"><a href="#cb1-870" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-871"><a href="#cb1-871" aria-hidden="true" tabindex="-1"></a><span class="in">      &lt;/pre&gt;</span></span>
<span id="cb1-872"><a href="#cb1-872" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb1-873"><a href="#cb1-873" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/li&gt;</span></span>
<span id="cb1-874"><a href="#cb1-874" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-875"><a href="#cb1-875" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/ul&gt;</span></span>
<span id="cb1-876"><a href="#cb1-876" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-877"><a href="#cb1-877" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/details&gt;</span></span>
<span id="cb1-878"><a href="#cb1-878" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-879"><a href="#cb1-879" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;details&gt;</span></span>
<span id="cb1-880"><a href="#cb1-880" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-881"><a href="#cb1-881" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;summary&gt;</span>Python Code Example:<span class="kw">&lt;/summary&gt;</span></span>
<span id="cb1-882"><a href="#cb1-882" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-883"><a href="#cb1-883" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;ul&gt;</span></span>
<span id="cb1-884"><a href="#cb1-884" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-885"><a href="#cb1-885" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;li&gt;</span></span>
<span id="cb1-886"><a href="#cb1-886" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-887"><a href="#cb1-887" aria-hidden="true" tabindex="-1"></a><span class="in">```{=html}</span></span>
<span id="cb1-888"><a href="#cb1-888" aria-hidden="true" tabindex="-1"></a><span class="in">&lt;pre&gt;</span></span>
<span id="cb1-889"><a href="#cb1-889" aria-hidden="true" tabindex="-1"></a><span class="in">    </span></span>
<span id="cb1-890"><a href="#cb1-890" aria-hidden="true" tabindex="-1"></a><span class="in"># Multi-Step (Hierarchical Regression) in Python</span></span>
<span id="cb1-891"><a href="#cb1-891" aria-hidden="true" tabindex="-1"></a><span class="in">import pandas as pd</span></span>
<span id="cb1-892"><a href="#cb1-892" aria-hidden="true" tabindex="-1"></a><span class="in">import numpy as np</span></span>
<span id="cb1-893"><a href="#cb1-893" aria-hidden="true" tabindex="-1"></a><span class="in">import statsmodels.api as sm</span></span>
<span id="cb1-894"><a href="#cb1-894" aria-hidden="true" tabindex="-1"></a><span class="in">from sklearn.datasets import load_iris</span></span>
<span id="cb1-895"><a href="#cb1-895" aria-hidden="true" tabindex="-1"></a><span class="in">from sklearn.model_selection import train_test_split</span></span>
<span id="cb1-896"><a href="#cb1-896" aria-hidden="true" tabindex="-1"></a><span class="in">from sklearn.metrics import mean_squared_error</span></span>
<span id="cb1-897"><a href="#cb1-897" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-898"><a href="#cb1-898" aria-hidden="true" tabindex="-1"></a><span class="in"># Load Iris data</span></span>
<span id="cb1-899"><a href="#cb1-899" aria-hidden="true" tabindex="-1"></a><span class="in">iris = load_iris()</span></span>
<span id="cb1-900"><a href="#cb1-900" aria-hidden="true" tabindex="-1"></a><span class="in">X = pd.DataFrame(iris.data, columns=iris.feature_names)</span></span>
<span id="cb1-901"><a href="#cb1-901" aria-hidden="true" tabindex="-1"></a><span class="in">y = iris.target</span></span>
<span id="cb1-902"><a href="#cb1-902" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-903"><a href="#cb1-903" aria-hidden="true" tabindex="-1"></a><span class="in"># Split the data into training and testing sets</span></span>
<span id="cb1-904"><a href="#cb1-904" aria-hidden="true" tabindex="-1"></a><span class="in">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)</span></span>
<span id="cb1-905"><a href="#cb1-905" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-906"><a href="#cb1-906" aria-hidden="true" tabindex="-1"></a><span class="in"># Step 1: Regression on a subset of predictors</span></span>
<span id="cb1-907"><a href="#cb1-907" aria-hidden="true" tabindex="-1"></a><span class="in">predictors_step1 = ['sepal length (cm)', 'sepal width (cm)']</span></span>
<span id="cb1-908"><a href="#cb1-908" aria-hidden="true" tabindex="-1"></a><span class="in">X_train_step1 = sm.add_constant(X_train[predictors_step1])</span></span>
<span id="cb1-909"><a href="#cb1-909" aria-hidden="true" tabindex="-1"></a><span class="in">model_step1 = sm.OLS(y_train, X_train_step1)</span></span>
<span id="cb1-910"><a href="#cb1-910" aria-hidden="true" tabindex="-1"></a><span class="in">results_step1 = model_step1.fit()</span></span>
<span id="cb1-911"><a href="#cb1-911" aria-hidden="true" tabindex="-1"></a><span class="in">y_pred_step1 = results_step1.predict(sm.add_constant(X_test[predictors_step1]))</span></span>
<span id="cb1-912"><a href="#cb1-912" aria-hidden="true" tabindex="-1"></a><span class="in">mse_step1 = mean_squared_error(y_test, y_pred_step1)</span></span>
<span id="cb1-913"><a href="#cb1-913" aria-hidden="true" tabindex="-1"></a><span class="in">print("Model Summary - Step 1:")</span></span>
<span id="cb1-914"><a href="#cb1-914" aria-hidden="true" tabindex="-1"></a><span class="in">print(results_step1.summary())</span></span>
<span id="cb1-915"><a href="#cb1-915" aria-hidden="true" tabindex="-1"></a><span class="in">print("Mean Squared Error - Step 1:", mse_step1)</span></span>
<span id="cb1-916"><a href="#cb1-916" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-917"><a href="#cb1-917" aria-hidden="true" tabindex="-1"></a><span class="in"># Step 2: Regression with additional predictors</span></span>
<span id="cb1-918"><a href="#cb1-918" aria-hidden="true" tabindex="-1"></a><span class="in">predictors_step2 = ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)']</span></span>
<span id="cb1-919"><a href="#cb1-919" aria-hidden="true" tabindex="-1"></a><span class="in">X_train_step2 = sm.add_constant(X_train[predictors_step2])</span></span>
<span id="cb1-920"><a href="#cb1-920" aria-hidden="true" tabindex="-1"></a><span class="in">model_step2 = sm.OLS(y_train, X_train_step2)</span></span>
<span id="cb1-921"><a href="#cb1-921" aria-hidden="true" tabindex="-1"></a><span class="in">results_step2 = model_step2.fit()</span></span>
<span id="cb1-922"><a href="#cb1-922" aria-hidden="true" tabindex="-1"></a><span class="in">y_pred_step2 = results_step2.predict(sm.add_constant(X_test[predictors_step2]))</span></span>
<span id="cb1-923"><a href="#cb1-923" aria-hidden="true" tabindex="-1"></a><span class="in">mse_step2 = mean_squared_error(y_test, y_pred_step2)</span></span>
<span id="cb1-924"><a href="#cb1-924" aria-hidden="true" tabindex="-1"></a><span class="in">print("Model Summary - Step 2:")</span></span>
<span id="cb1-925"><a href="#cb1-925" aria-hidden="true" tabindex="-1"></a><span class="in">print(results_step2.summary())</span></span>
<span id="cb1-926"><a href="#cb1-926" aria-hidden="true" tabindex="-1"></a><span class="in">print("Mean Squared Error - Step 2:", mse_step2)</span></span>
<span id="cb1-927"><a href="#cb1-927" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-928"><a href="#cb1-928" aria-hidden="true" tabindex="-1"></a><span class="in"># Step 3: Regression with all predictors</span></span>
<span id="cb1-929"><a href="#cb1-929" aria-hidden="true" tabindex="-1"></a><span class="in">X_train_step3 = sm.add_constant(X_train)</span></span>
<span id="cb1-930"><a href="#cb1-930" aria-hidden="true" tabindex="-1"></a><span class="in">model_step3 = sm.OLS(y_train, X_train_step3)</span></span>
<span id="cb1-931"><a href="#cb1-931" aria-hidden="true" tabindex="-1"></a><span class="in">results_step3 = model_step3.fit()</span></span>
<span id="cb1-932"><a href="#cb1-932" aria-hidden="true" tabindex="-1"></a><span class="in">y_pred_step3 = results_step3.predict(sm.add_constant(X_test))</span></span>
<span id="cb1-933"><a href="#cb1-933" aria-hidden="true" tabindex="-1"></a><span class="in">mse_step3 = mean_squared_error(y_test, y_pred_step3)</span></span>
<span id="cb1-934"><a href="#cb1-934" aria-hidden="true" tabindex="-1"></a><span class="in">print("Model Summary - Step 3:")</span></span>
<span id="cb1-935"><a href="#cb1-935" aria-hidden="true" tabindex="-1"></a><span class="in">print(results_step3.summary())</span></span>
<span id="cb1-936"><a href="#cb1-936" aria-hidden="true" tabindex="-1"></a><span class="in">print("Mean Squared Error - Step 3:", mse_step3)</span></span>
<span id="cb1-937"><a href="#cb1-937" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-938"><a href="#cb1-938" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-939"><a href="#cb1-939" aria-hidden="true" tabindex="-1"></a><span class="in"># COMPARING MSE</span></span>
<span id="cb1-940"><a href="#cb1-940" aria-hidden="true" tabindex="-1"></a><span class="in">print("Mean Squared Error - Step 1:", mse_step1)</span></span>
<span id="cb1-941"><a href="#cb1-941" aria-hidden="true" tabindex="-1"></a><span class="in">print("Mean Squared Error - Step 2:", mse_step2)</span></span>
<span id="cb1-942"><a href="#cb1-942" aria-hidden="true" tabindex="-1"></a><span class="in">print("Mean Squared Error - Step 3:", mse_step3)</span></span>
<span id="cb1-943"><a href="#cb1-943" aria-hidden="true" tabindex="-1"></a><span class="in">      &lt;/pre&gt;</span></span>
<span id="cb1-944"><a href="#cb1-944" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb1-945"><a href="#cb1-945" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/li&gt;</span></span>
<span id="cb1-946"><a href="#cb1-946" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-947"><a href="#cb1-947" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/ul&gt;</span></span>
<span id="cb1-948"><a href="#cb1-948" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-949"><a href="#cb1-949" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/details&gt;</span></span>
<span id="cb1-950"><a href="#cb1-950" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-951"><a href="#cb1-951" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;details&gt;</span></span>
<span id="cb1-952"><a href="#cb1-952" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-953"><a href="#cb1-953" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;summary&gt;</span>STATA Code Example:<span class="kw">&lt;/summary&gt;</span></span>
<span id="cb1-954"><a href="#cb1-954" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-955"><a href="#cb1-955" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;ul&gt;</span></span>
<span id="cb1-956"><a href="#cb1-956" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-957"><a href="#cb1-957" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;li&gt;</span></span>
<span id="cb1-958"><a href="#cb1-958" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-959"><a href="#cb1-959" aria-hidden="true" tabindex="-1"></a><span class="in">```{=html}</span></span>
<span id="cb1-960"><a href="#cb1-960" aria-hidden="true" tabindex="-1"></a><span class="in">&lt;pre&gt;</span></span>
<span id="cb1-961"><a href="#cb1-961" aria-hidden="true" tabindex="-1"></a><span class="in">        // Multi-Step (Hierarchical Regression) in STATA</span></span>
<span id="cb1-962"><a href="#cb1-962" aria-hidden="true" tabindex="-1"></a><span class="in">        // Step 1</span></span>
<span id="cb1-963"><a href="#cb1-963" aria-hidden="true" tabindex="-1"></a><span class="in">        regress recovery_time age gender</span></span>
<span id="cb1-964"><a href="#cb1-964" aria-hidden="true" tabindex="-1"></a><span class="in">        </span></span>
<span id="cb1-965"><a href="#cb1-965" aria-hidden="true" tabindex="-1"></a><span class="in">        // Step 2</span></span>
<span id="cb1-966"><a href="#cb1-966" aria-hidden="true" tabindex="-1"></a><span class="in">        regress recovery_time age gender severity</span></span>
<span id="cb1-967"><a href="#cb1-967" aria-hidden="true" tabindex="-1"></a><span class="in">        </span></span>
<span id="cb1-968"><a href="#cb1-968" aria-hidden="true" tabindex="-1"></a><span class="in">        // Step 3</span></span>
<span id="cb1-969"><a href="#cb1-969" aria-hidden="true" tabindex="-1"></a><span class="in">        regress recovery_time age gender severity treatment comorbidities</span></span>
<span id="cb1-970"><a href="#cb1-970" aria-hidden="true" tabindex="-1"></a><span class="in">      &lt;/pre&gt;</span></span>
<span id="cb1-971"><a href="#cb1-971" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb1-972"><a href="#cb1-972" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/li&gt;</span></span>
<span id="cb1-973"><a href="#cb1-973" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-974"><a href="#cb1-974" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/ul&gt;</span></span>
<span id="cb1-975"><a href="#cb1-975" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-976"><a href="#cb1-976" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/details&gt;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div></div></div></div></div>
</div> <!-- /content -->



</body></html>